<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[常用技术网站及工具文档传送门]]></title>
    <url>%2F2017%2F08%2F29%2F%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%BD%91%E7%AB%99%E5%8F%8A%E5%B7%A5%E5%85%B7%E6%96%87%E6%A1%A3%E4%BC%A0%E9%80%81%E9%97%A8%2F</url>
    <content type="text"><![CDATA[IT资讯 名称 地址 CSDN http://www.csdn.net/ 51CTO http://www.51cto.com/ 开源中国社区 https://www.oschina.net/ 技术网站 名称 地址 掘金 https://juejin.im/ ITeye http://www.iteye.com/ 博客园 https://www.cnblogs.com/ 并发编程网 http://ifeve.com/ ImportNew http://www.importnew.com/ segmentfault https://segmentfault.com/ IBM developerWorks https://www.ibm.com/developerworks/cn/ 收藏博客 博主名字 地址 李震 http://dyingbleed.com/ yeasy https://www.gitbook.com/@yeasy 刘正阳 https://liuzhengyang.github.io/ v_JULY_v http://blog.csdn.net/v_july_v 程序猿DD http://blog.didispace.com/ 真实的归宿 http://blog.csdn.net/hguisu 程序媛想事儿 http://blog.csdn.net/lanxuezaipiao MoreWindows http://blog.csdn.net/morewindows 泥瓦匠BYSocket http://www.bysocket.com/ SherryWang0622 http://blog.csdn.net/supersnow0622 工具网站 名称 地址 码市 https://mart.coding.net/ 马克飞象 https://maxiang.io/ ProcessOn https://www.processon.com/ 闹钟AeroTimer http://aerotimer.com/ 七牛开发者平台 https://portal.qiniu.com/signin MVN Repository https://mvnrepository.com/ Amazon WebService https://aws.amazon.com/cn/ 官方技术文档 名称 地址 Apache Hadoop http://hadoop.apache.org/ Apache Log4j 2 https://logging.apache.org/log4j/2.x/ Apache ZooKeeper https://zookeeper.apache.org/ Docker https://docs.docker.com/ Dubbo http://dubbo.io/ Echarts http://echarts.baidu.com/index.html Editor.md https://pandao.github.io/editor.md/ Elasticsearch https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html FreeMarker https://www.zheng-hang.com/chm/freemarker2_3_24/toc.html Git https://git-scm.com/ memcached https://github.com/memcached/memcached/wiki MongoDB http://docs.mongoing.com/manual-zh/ Mybatis http://www.mybatis.org/mybatis-3/zh/index.html RabbitMQ https://www.rabbitmq.com/getstarted.html Scrapy http://scrapy-chs.readthedocs.io/zh_CN/1.0/index.html Spring https://spring.io/docs/reference Spring Boot https://projects.spring.io/spring-boot/ Spring Cloud https://springcloud.cc/ Storm http://storm.apachecn.org/releases/cn/1.1.0/index.html wangEditor3 https://www.kancloud.cn/wangfupeng/wangeditor3/332599 大厂资源链接 名称 地址 百度EFE（Excellent FrontEnd） http://efe.baidu.com/ 百度Web前端研发部FEX http://fex.baidu.com/ 百度企业产品用户体验中心 http://eux.baidu.com/ 阿里中间件团队博客 http://jm.taobao.org/ 阿里聚安全 https://jaq.alibaba.com/community/index.htm 阿里用户体验设计部UED http://www.aliued.cn/ 阿里云栖社区 https://yq.aliyun.com/ 阿里云 https://www.aliyun.com 阿里淘宝前端团队（FED） http://taobaofed.org/ 腾讯前端IMWEB团队 http://imweb.github.io/ 腾讯全端AlloyTeam团队 http://www.alloyteam.com/ 腾讯ISUX-社交用户体验设计 http://isux.tencent.com/ 腾讯MXD移动互联网设计中心 http://mxd.tencent.com/ 腾讯CDC http://cdc.tencent.com/ 腾讯游戏官方设计团队TGideas http://tgideas.qq.com/ 腾讯游戏DBA团队 http://tencentdba.com/ 腾讯财付通设计中心TID http://tid.tenpay.com/ 腾讯云 https://cloud.tencent.com/community 美团点评技术团队 https://tech.meituan.com/ 携程设计委员会 http://ued.ctrip.com/blog/ 京东设计中心JDC http://jdc.jd.com/ 京东前端凹凸实验室 https://aotu.io/index.html 360前端团队-奇舞团 https://75team.com/ 360技术博客 http://blogs.360.cn/ 360用户体验设计中心UXC http://uxc.360.cn/ 网易用户体验中心UEDC http://uedc.163.com/ 搜狐畅游视觉设计中心 http://vc.changyou.com/index.shtml 七牛云 http://blog.qiniu.com/ Glow技术团队博客 http://tech.glowing.com/cn/ GitHub组织 名称 地址 Apache https://github.com/apache Java EE https://github.com/javaee/ Oracle https://github.com/oracle Facebook https://github.com/facebook Twitter https://github.com/twitter elastic https://github.com/elastic memcached https://github.com/memcached Alibaba https://github.com/alibaba Taobao https://github.com/taobao Tencent https://github.com/Tencent 腾讯云 https://github.com/tencentyun WePayUI https://github.com/wepayui 美团点评 https://github.com/meituan-dianping YY https://github.com/YYOpenSource shadowsocks https://github.com/shadowsocks OnePlus https://github.com/OnePlusOSS 参考&amp;引用更新时间发布时间 ： 2017-08-29]]></content>
  </entry>
  <entry>
    <title><![CDATA[VPN搭建:亚马逊EC2+Shadowsocks]]></title>
    <url>%2F2017%2F08%2F16%2FVPN%E6%90%AD%E5%BB%BA-%E4%BA%9A%E9%A9%AC%E9%80%8AEC2-Shadowsocks%2F</url>
    <content type="text"><![CDATA[创建ec2实例具体创建过程不再赘述，下面贴出一张创建成果之后的示例图： SSH登录ec2实例一般我们通过PuTTY或者Xshell远程连接ec2实例，下面具体介绍一下方法 PuTTY此处不再详细解释，具体请参考AWS官方文档 使用 PuTTY 从 Windows 连接到 Linux 实例 Xshell 具体配置步骤以下命令均在最高权限用户 root 下运行,通过sudo -s获取超级管理员权限 安装shadowsocks服务端123apt-get update // 更新apt-getapt-get install python-pip // 安装python包管理工具pippip install shadowsocks // 安装shadowsocks 配置使用Vi编辑器创建名为shadowsocks.json的配置文件 1vi /etc/shadowsocks.json vi打开文件后，按i进入编辑模式 单一端口配置： 12345678910&#123; &quot;server&quot;: &quot;0.0.0.0&quot;, #或者为服务器ip地址 &quot;server_port&quot;: 1106, #端口 &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;: 1080, &quot;password&quot;: &quot;123123123&quot;, #连接密码 &quot;timeout&quot;: 300, &quot;method&quot;: &quot;aes-256-cfb&quot;, &quot;fast_open&quot;: false&#125; 多端口配置： 12345678910&#123; “server”:”0.0.0.0”, “port_password”: &#123; “端口1”: “连接密码1”, “端口2” : “连接密码2” &#125;, “timeout”:300, “method”:”aes-256-cfb”, “fast_open”: false&#125; 推荐一个Json在线格式化工具编辑完成后，按Esc键，输入:wq之后会保存修改并退出vi编辑器。 在这里通过下表看一下配置文件中各项代表了什么 配置项 配置文件说明 server 服务端监听地址(IPv4或IPv6) server_port 服务端端口，一般为443 local_address 本地监听地址，缺省为127.0.0.1 local_port 本地监听端口，一般为1080 password 用以加密的密匙 timeout 超时时间（秒） method 加密方法，默认为aes-256-cfb，更多请查阅Encryption fast_open 是否启用TCP-Fast-Open，true或者false workers worker数量，如果不理解含义请不要改（这个只在Unix和Linux下有用） 启动Shadowsocks服务器输入以下命令来启动Shadowsocks 1ssserver -c /etc/shadowsocks.json -d start 编辑EC2入站规则 回到ec2控制台，右键之前创建的实例，如下图选择更改安全组 “编辑入站规则”-&gt;”添加规则”，类型为“所有ICMP-IPv4” 到这里VPN服务器就搭建完毕了 使用Shadowsocks客户端下载客户端windows 客户端下载地址 ： https://github.com/shadowsocks/shadowsocks-windows/releases 配置客户端 此处服务器地址应该填写公有DNS(IPv4)而不是IPv4公有IP 点击确定就可以使用 参考&amp;引用shadowsocks官网Shadowsocks的项目WikiVPN搭建:亚马逊EC2+Shadowsocks使用 Shadowsocks 自建翻墙服务器，实现全平台 100% 翻墙无障碍 更新时间发布时间 ： 2017-08-16]]></content>
      <tags>
        <tag>VPN</tag>
        <tag>AWS</tag>
        <tag>EC2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[游戏] Linux 上搭建饥荒联机版 Don't Starve Together服务器]]></title>
    <url>%2F2017%2F07%2F15%2F%E6%B8%B8%E6%88%8F-Linux-%E4%B8%8A%E6%90%AD%E5%BB%BA%E9%A5%A5%E8%8D%92%E8%81%94%E6%9C%BA%E7%89%88-Don-t-Starve-Together%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[安装依赖Ubuntu 64位环境： 1sudo apt-get install libstdc++6:i386 libgcc1:i386 libcurl4-gnutls-dev:i386 安装SteamCMD和DST下载SteamCMD： 123mkdir ~/steamcmd cd ~/steamcmdwget http://media.steampowered.com/installer/steamcmd_linux.tar.gz 解压并运行安装 12tar -xvzf steamcmd_linux.tar.gz./steamcmd.sh 在 steam &gt; 模式下，登录及安装游戏包 1234login anonymous force_install_dir ../DSTapp_update 343050 validatequit 在上面的命令中，第一行以匿名方式登录，当然你可以登陆你自己的steamID；第二行是指定安装路径，将程序安装到steamcmd的同级目录下；第三行的343050 是Don’t Starve Together 在 Steam 平台中的 ID。 配置Don’t Starve Together生成默认配置文件12cd ~/DST/bin./dontstarve_dedicated_server_nullrenderer 当看到一下提示 1234[200] Account Failed (6): &quot;E_INVALID_TOKEN&quot;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Your Server Will Not Start !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 按Ctrl+C中断，然后完善生成的默认配置 之前查看很多资料都是需要在~/.klei/DoNotStarveTogether路径下写配置文件，现在该路径已经更改为~/.klei/DoNotStarveTogether/Cluster_1 依照以下文件结构新建文件夹及文件1234567891011Cluster_1├── cluster.ini├── cluster_token.txt├── Caves│ ├── modoverrides.lua│ ├── server.ini│ └── worldgenoverride.lua└── Master ├── modoverrides.lua ├── server.ini └── worldgenoverride.lua #重写世界具体物品数量等参数配置 设置Token 点击个人资料 点击Generate Server Token的按钮，将生成游戏令牌，将该Token复制到cluster_token.txt中 设置服务器全局变量12cd ~/.klei/DoNotStarveTogether/Cluster_1sudo vi cluster.ini 填入以下内容： 1234567891011121314151617181920212223[GAMEPLAY]game_mode = survival # Endless无尽模式；Wildern荒野模式；Survival生存模式max_players = 6 # 最大玩家数，1-64任意一个数pvp = false #pause_when_empty = true # 世界没人时是否自动暂停enable_snapshots = trueenable_autosaver = true[NETWORK]cluster_description = Live it # 游戏房间描述cluster_name = LiveIt007 # 游戏名称cluster_intention = cooperative # 游戏模式 cluster_password = 123123123 # 密码[MISC]console_enabled = true # 控制台[SHARD]shard_enabled = true # 地下世界是否启动 bind_ip = 127.0.0.1 # 固定IPmaster_ip = 127.0.0.1 # 地上世界IPmaster_port = 10889 # 地上世界端口cluster_key = supersecretkey # 地下世界连接地上世界的钥匙 按ESC，输入：wq 保存并退出vi编辑器。 设置局部配置12cd ~/.klei/DoNotStarveTogether/Cluster_1/Mastersudo vi server.ini 填入 123456789[NETWORK]server_port = 11000[SHARD]is_master = true[STEAM]master_server_port = 27018authentication_port = 8768 设置地下世界的配置12cd ~/.klei/DoNotStarveTogether/Cluster_1/Cavessudo vi server.ini 填入 12345678910[NETWORK]server_port = 11001[SHARD]is_master = falsename = Caves[STEAM]master_server_port = 27019authentication_port = 8769 配置世界资源生成12cd ~/.klei/DoNotStarveTogether/Cluster_1/Cavessudo vi worldgenoverride.lua 填入 1234return &#123; override_enabled = true, preset = &quot;DST_CAVE&quot;,&#125; 启动服务器创建启动服务器脚本 12cd ~/sudo vi runDST.sh 填入 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bashsteamcmd_dir=&quot;$HOME/steamcmd&quot; install_dir=&quot;$HOME/DST&quot; cluster_name=&quot;Cluster_1&quot;dontstarve_dir=&quot;$HOME/.klei/DoNotStarveTogether&quot;function fail()&#123; echo Error: &quot;$@&quot; &gt;&amp;2 exit 1&#125;function check_for_file()&#123; if [ ! -e &quot;$1&quot; ]; then fail &quot;Missing file: $1&quot; fi&#125;cd &quot;$steamcmd_dir&quot; || fail &quot;Missing $steamcmd_dir directory!&quot;check_for_file &quot;$steamcmd_dir/steamcmd.sh&quot;check_for_file &quot;$dontstarve_dir/$cluster_name/cluster.ini&quot;check_for_file &quot;$dontstarve_dir/$cluster_name/cluster_token.txt&quot;check_for_file &quot;$dontstarve_dir/$cluster_name/Master/server.ini&quot;check_for_file &quot;$dontstarve_dir/$cluster_name/Caves/server.ini&quot;.~/steamcmd/steamcmd.sh +force_install_dir &quot;$install_dir&quot; +login anonymous +app_update 343050 validate +quitcheck_for_file &quot;$install_dir/bin&quot;cd &quot;$install_dir/bin&quot; || fail run_shared=(./dontstarve_dedicated_server_nullrenderer)run_shared+=(-console)run_shared+=(-cluster &quot;$cluster_name&quot;)run_shared+=(-monitor_parent_process $$)&quot;$&#123;run_shared[@]&#125;&quot; -shard Caves | sed &apos;s/^/Caves: /&apos; &amp;&quot;$&#123;run_shared[@]&#125;&quot; -shard Master | sed &apos;s/^/Master: /&apos; 给脚本赋予执行权限 1sudo chmod u+x ~/runDST.sh 执行脚本，开启服务器 1sudo ~/runDST.sh 当出现下面的日志时，说明服务器启动成功了 此时在客户端搜索在cluster.ini文件中配置的房间名，你就能找到你所创建的房间了 进阶技能增加Mod饥荒通过/DST/mods路径下的dedicated_server_mods_setup.lua文件确认需要下载那些mod。首先去创意工坊找些 Mod，并获得其 id，或者找些 Mod 合集，将 Mod id 按以下形式（换行复制粘贴）保存在文件中。以下是完整文件内容 12345678910111213141516171819202122232425262728293031--There are two functions that will install mods, ServerModSetup and ServerModCollectionSetup. Put the calls to the functions in this file and they will be executed on boot. --ServerModSetup takes a string of a specific mod's Workshop id. It will download and install the mod to your mod directory on boot. --The Workshop id can be found at the end of the url to the mod's Workshop page. --Example: http://steamcommunity.com/sharedfiles/filedetails/?id=350811795 --ServerModSetup("350811795") --ServerModCollectionSetup takes a string of a specific mod's Workshop id. It will download all the mods in the collection and install them to the mod directory on boot. --The Workshop id can be found at the end of the url to the collection's Workshop page. --Example: http://steamcommunity.com/sharedfiles/filedetails/?id=379114180 --ServerModCollectionSetup("379114180") ServerModSetup("345692228") --"Minimap HUD"ServerModSetup("347079953") --"Display food values"ServerModSetup("351325790") --"Geometric Placement"ServerModSetup("367546858") --"Chinese Language Pack"ServerModSetup("375850593") --"Extra Equip Slots"ServerModSetup("375859599") --"Health Info"ServerModSetup("376333686") --"Combined Status"ServerModSetup("378160973") --"Global Positions"ServerModSetup("444438334") --"DJPaul's Sort Inventory"ServerModSetup("458587300") --"Fast Travel"ServerModSetup("458940297") --"Food Values - Item Tooltips (Server and Client)"ServerModSetup("462434129") --"Restart"ServerModSetup("556027744") --"SUMMON BIGFOOT( With Old Bell)"ServerModSetup("572538624") --"Chinese Plus"ServerModSetup("623749604") --" Storeroom"ServerModSetup("928706300") --"To Do Chores"ServerModSetup("949822556") --"Egg Pain Together" --ServerModCollectionSetup("id") 上面是我常用的几个Mod。但是dedicated_server_mods_setup.lua只是用于下载Mod，至于Mod是否启用以及配置则是modoverrides.lua 文件的功能。 1234567891011121314151617181920212223242526return &#123;["workshop-345692228"] = &#123; enabled = true &#125;,["workshop-347079953"] = &#123; enabled = true &#125;,["workshop-351325790"] = &#123; enabled = true &#125;,["workshop-367546858"] = &#123; enabled = true &#125;,["workshop-375850593"] = &#123; enabled = true &#125;,["workshop-375859599"] = &#123; enabled = true &#125;,["workshop-376333686"] = &#123; enabled = true &#125;,["workshop-378160973"] = &#123; enabled = true &#125;,["workshop-444438334"] = &#123; enabled = true, configuration_options = &#123; keybind = 103, maxLights = 2, backpackCategory = "food" &#125;&#125;,["workshop-458587300"] = &#123; enabled = true &#125;,["workshop-458940297"] = &#123; enabled = true &#125;,["workshop-462434129"] = &#123; enabled = true &#125;,["workshop-556027744"] = &#123; enabled = true &#125;,["workshop-572538624"] = &#123; enabled = true &#125;,["workshop-623749604"] = &#123; enabled = true &#125;,["workshop-928706300"] = &#123; enabled = true &#125;,["workshop-949822556"] = &#123; enabled = true &#125;&#125; 要注意，这两个文件的Mod Id是一一对应的。同时，将modoverrides.lua分别复制到Master和Caves文件下。 设定管理员在~/.klei/DoNotStarveTogether/Cluster_1路径下创建adminlist.txt文件，然后将想成为管理员的玩家的用户ID一行一个写入其中。获取用户ID的两种方法： 1. 让该玩家加入游戏，再查看日志，你会在日志中找到 KU_ 开头的一串用户 id 2. 让该玩家点击游戏主页面的 Account 按钮（和获得 token 一样），在页面中会有用户 id 下面是例子 123456KU_3N5kE2ZpKU_BJY3CxYTKU_DF1orNGAKU_FAd2Yr8mKU_vvbUjgIX 用户黑名单，用户白名单同设定管理员操作一样，在~/.klei/DoNotStarveTogether/Cluster_1路径下分别创建blocklist.txt、whitelist.txt，然后将用户ID写入即可。 下面是最终的文件结构 1234567891011121314Cluster_1├── cluster.ini├── cluster_token.txt├── adminlist.txt├── blocklist.txt├── whitelist.txt├── Caves│ ├── modoverrides.lua│ ├── server.ini│ └── worldgenoverride.lua└── Master ├── modoverrides.lua ├── server.ini └── worldgenoverride.lua #重写世界具体物品数量等参数配置 参考&amp;引用关于启动参数的引用SteamCMD 使用方法关于ini文件里面参数的引用官方论坛，关于linux的开服Klei 建议的 Don’t Strave Together Dedicated Server 搭建指南 更新时间发布时间 ： 2017-07-15]]></content>
      <tags>
        <tag>Ubuntu</tag>
        <tag>游戏</tag>
        <tag>饥荒</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下添加虚拟内存]]></title>
    <url>%2F2017%2F07%2F15%2FLinux%E4%B8%8B%E6%B7%BB%E5%8A%A0%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[背景因为最近跟朋友在玩饥荒，刚好手里有腾讯云的1核 1GB的免费云服务器，就想着自己搭一个服务器，但是当真正配置完之后，发现如果开地穴的话1G内存并不能满足需求，要么花钱要么就采用虚拟内存的方法，将硬盘空间划过来一部分当内存。 方法Linux操作系统有两种实现虚拟内存的方法：交换分区(swap分区)和交换文件(swap文件)。采用交换分区的办法其实就是新建一个分区，然后将该分区挂载作为交换空间，方法步骤与传统的新建分区一样。只不过格式化分区和挂载分区分别采用mkswap和swapon命令。我在这里使用了交换文件的方法。 具体实现首先我们需要查看硬盘信息和挂载信息以确定分区的大小 12sudo fdisk -lsudo df -Th 然后查看当前系统的内存大小 1sudo free -h 可以看到原来的内存大小，不足1G 创建swapfile文件，大小指定为2G 1dd if=/dev/zero of=/mnt/swapfile bs=1M count=2048 if表示input_file输入文件，of表示output_file输出文件，bs表示block_size块大小，count表示计数 然后，格式化交换文件： 1mkswap /mnt/swapfile 之后，挂载交换文件： 1swapon /mnt/swapfile 现在再查看当前系统的内存大小，如图所示，新增加了2G 为了保证开机自动加载虚拟内存，还需要在/etc/fstab文件中加入如下命令： 1/mnt/swapfile swap swap defaults 0 0 这样就完成了 参考&amp;引用linux下如何添加虚拟内存 更新时间发布时间 ： 2017-07-15]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>虚拟内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[分享] Spring Boot学习资料整理]]></title>
    <url>%2F2017%2F02%2F25%2F%E5%88%86%E4%BA%AB-Spring-Boot%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言最近一段时间在自学Spring Boot的相关知识，做了一些学习笔记，在学习过程中也找到几位大神写的相当不错的Spring Boot系列学习资料，在这里整理一下，做个传送门，以便今后学习。 《Spring Boot基础教程》系列《Spring Boot 那些事》系列《SpringBoot非官方教程》系列《Spring Boot系列文章》系列《重拾后端之Spring Boot》系列 重拾后端之Spring Boot（一）：REST API的搭建可以这样简单 重拾后端之Spring Boot（二）：MongoDB的无缝集成 重拾后端之Spring Boot（三）：找回熟悉的Controller，Service 重拾后端之Spring Boot（四）：使用JWT和Spring Security保护REST API 《学习 Spring Boot》系列 学习 Spring Boot（一）：第一个 Spring Boot 应用 学习 Spring Boot（二）：集成 MyBatis 和 Druid 学习 Spring Boot（三）：单元测试 学习 Spring Boot（四）：使用 Maven 构建 Scala 应用 学习 Spring Boot（五）：日志 学习 Spring Boot（六）：使用 SpringFox 生成接口文档 学习 Spring Boot（七）：集成 Apache Shiro 安全框架 学习 Spring Boot（八）：使用 Redis 缓存 学习 Spring Boot（九）：使用 RabbitMQ 消息队列 单点文章 基于Spring Boot/Spring Session/Redis的分布式Session共享解决方案 参考&amp;引用更新时间发布时间 ： 2017-02-25]]></content>
      <tags>
        <tag>分享</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新认识集合框架之HashMap]]></title>
    <url>%2F2016%2F12%2F03%2F%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E4%B9%8BHashMap%2F</url>
    <content type="text"><![CDATA[简介在官方文档中是这样描述HashMap的： Hash table based implementation of the Map interface. This implementation provides all of the optional map operations, and permits null values and the null key. (The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.) This class makes no guarantees as to the order of the map; in particular, it does not guarantee that the order will remain constant over time. 几个关键的信息：基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。 内部实现存储结构从结构实现来讲，HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的，如下如所示。 从源码可知，HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。我们来看Node[JDK1.8]是何物。 1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125; public final K getKey()&#123; ... &#125; public final V getValue() &#123; ... &#125; public final String toString() &#123; ... &#125; public final int hashCode() &#123; ... &#125; public final V setValue(V newValue) &#123; ... &#125; public final boolean equals(Object o) &#123; ... &#125;&#125; Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。 功能实现put函数的实现HashMap的put方法执行过程可以通过下图来理解 ①. 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容；②. 根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，则转向③；③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 JDK1.8HashMap的put方法源码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public V put(K key, V value) &#123; // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①：tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 步骤③：节点key存在，直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 步骤④：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key,value,null); //链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // key已经存在直接覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 步骤⑥：超过最大容量 就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; get函数的实现在理解了put之后，get就很简单了。大致思路如下： bucket里的第一个节点，直接命中； 如果有冲突，则通过key.equals(k)去查找对应的entry若为树，则在树中通过key.equals(k)查找，O(logn)；若为链表，则在链表中通过key.equals(k)查找，O(n)。具体代码的实现如下： 123456789101112131415161718192021222324252627public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 直接命中 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 未命中 if ((e = first.next) != null) &#123; // 在树中get if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 在链表中get do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; hash函数的实现在get和put的过程中，计算下标时，先对hashCode进行hash操作，然后再通过hash值进一步计算下标，如下图所示： 在对hashCode()计算hash时具体实现是这样的： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 可以看到这个函数大概的作用就是：高16bit不变，低16bit和高16bit做了一个异或。其中代码注释是这样写的： Computes key.hashCode() and spreads (XORs) higher bits of hash to lower. Because the table uses power-of-two masking, sets of hashes that vary only in bits above the current mask will always collide. (Among known examples are sets of Float keys holding consecutive whole numbers in small tables.) So we apply a transform that spreads the impact of higher bits downward. There is a tradeoff between speed, utility, and quality of bit-spreading. Because many common sets of hashes are already reasonably distributed (so don’t benefit from spreading), and because we use trees to handle large sets of collisions in bins, we just XOR some shifted bits in the cheapest possible way to reduce systematic lossage, as well as to incorporate impact of the highest bits that would otherwise never be used in index calculations because of table bounds. 在设计hash函数时，因为目前的table长度n为2的幂，而计算下标的时候，是这样实现的(使用&amp;位操作，而非%求余)： 1(n - 1) &amp; hash 设计者认为这方法很容易发生碰撞。为什么这么说呢？不妨思考一下，在n - 1为15(0x1111)时，其实散列真正生效的只是低4bit的有效位，当然容易碰撞了。 因此，设计者想了一个顾全大局的方法(综合考虑了速度、作用、质量)，就是把高16bit和低16bit异或了一下。设计者还解释到因为现在大多数的hashCode的分布已经很不错了，就算是发生了碰撞也用O(logn)的tree去做了。仅仅异或一下，既减少了系统的开销，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。 如果还是产生了频繁的碰撞，会发生什么问题呢？作者注释说，他们使用树来处理频繁的碰撞(we use trees to handle large sets of collisions in bins)，在JEP-180中，描述了这个问题： Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class. 之前已经提过，在获取HashMap的元素时，基本分两步： 首先根据hashCode()做hash，然后确定bucket的index； 如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。 在Java 8之前的实现中是用链表解决冲突的，在产生碰撞的情况下，进行get时，两步的时间复杂度是O(1)+O(n)。因此，当碰撞很厉害的时候n很大，O(n)的速度显然是影响速度的。 因此在Java 8中，利用红黑树替换链表，这样复杂度就变成了O(1)+O(logn)了，这样在n很大的时候，能够比较理想的解决这个问题，在Java 8：HashMap的性能提升一文中有性能测试的结果。 扩容机制在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。resize的注释是这样描述的： Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table. 大致意思就是说，当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。 怎么理解呢？例如我们从16扩展为32时，具体的变化如下所示： 因此元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。 下面是代码的具体实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384final Node&lt;K,V&gt;[] resize() &#123; // 将字段引用copy到局部变量表，这样在之后的使用时可以减少getField指令的调用。 Node&lt;K,V&gt;[] oldTab = table; // oldCap为原数组的大小或当空时为0 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 新的数组的大小是旧数组的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 当旧的的数组大小大于等于默认大小时，threshold也扩大一倍。 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) // 按照新的capacity创建新数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 将原数组中的数组复制到新数组中 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) // 如果e是该bucket唯一的一个元素，则直接赋值到新数组中。 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // TreeNode的情况则使用TreeNode中的split方法将这个树分成两个小树 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 否则则创建两个链表用来存放要放的数据，hash值&amp;oldCap为0的(即oldCap的1的位置的和hash值的同样的位置都是1，同样是基于capacity是2的次方这一前提)为low链表，反之为high链表, 通过这种方式将旧的数据分到两个链表中再放到各自对应余数的位置。 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 按照e.hash值区分放在loTail后还是hiTail后 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 处理完之后放到新数组中 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 线程安全问题为什么说HashMap是线程不安全的呢？它在多线程环境下，会发生什么情况呢？ resize死循环fail-fast其他问题能否让 HashMap 同步？1Map m = Collections.synchronizeMap(hashMap); 当两个对象的hashcode相同会发生什么？因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。在JDK1.8中如果链表的长度超过8，将会存储在红黑树中。 如果两个键的hashcode相同，你如何获取值对象？当我们get()方法，HashMap会使用键对象的hashcode找到bucket位置，因为对象储存在同一个bucket中，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。 为什么String, Interger这样的wrapper类适合作为键？String, Interger这样的wrapper类作为HashMap的键是再适合不过了，而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个field声明成final就能保证hashCode是不变的，那么请这么做吧。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这样就能提高HashMap的性能。 参考&amp;引用HashMap多线程死循环问题Java HashMap工作原理及实现Java 8系列之重新认识HashMap谈谈HashMap线程不安全的体现HashMap、Hashtable、HashSet 和 ConcurrentHashMap 的比较 更新时间发布时间 ： 2016-12-03]]></content>
      <categories>
        <category>《重新认识集合框架》</category>
      </categories>
      <tags>
        <tag>集合框架</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转载] Restful API 的设计规范]]></title>
    <url>%2F2016%2F10%2F29%2F%E8%BD%AC%E8%BD%BD-Restful-API-%E7%9A%84%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[本文总结了 RESTful API 设计相关的一些原则，只覆盖了常见的场景。有些规则只是针对自己项目而言，并非其他做法都是错误的。 URIURI 表示资源，资源一般对应服务器端领域模型中的实体类。 URI规范 不用大写； 用中杠-不用下杠_； 参数列表要encode； URI中的名词表示资源集合，使用复数形式。 资源集合 vs 单个资源URI表示资源的两种方式：资源集合、单个资源。资源集合： 12/zoos //所有动物园/zoos/1/animals //id为1的动物园中的所有动物 单个资源： 12/zoos/1 //id为1的动物园/zoos/1;2;3 //id为1，2，3的动物园 避免层级过深的URI/在url中表达层级，用于按实体关联关系进行对象导航，一般根据id导航。 过深的导航容易导致url膨胀，不易维护，如 GET /zoos/1/areas/3/animals/4，尽量使用查询参数代替路径中的实体导航，如GET /animals?zoo=1&amp;area=3； 对Composite资源的访问服务器端的组合实体必须在uri中通过父实体的id导航访问。 组合实体不是first-class的实体，它的生命周期完全依赖父实体，无法独立存在，在实现上通常是对数据库表中某些列的抽象，不直接对应表，也无id。一个常见的例子是 User — Address，Address是对User表中zipCode/country/city三个字段的简单抽象，无法独立于User存在。必须通过User索引到Address：GET /user/1/addresses RequestHTTP方法通过标准HTTP方法对资源CRUD：GET：查询 123GET /zoosGET /zoos/1GET /zoos/1/employees POST：创建单个资源。POST一般向“资源集合”型uri发起 12POST /animals //新增动物POST /zoos/1/employees //为id为1的动物园雇佣员工 PUT：更新单个资源（全量），客户端提供完整的更新后的资源。与之对应的是 PATCH，PATCH 负责部分更新，客户端提供要更新的那些字段。PUT/PATCH一般向“单个资源”型uri发起 12PUT /animals/1PUT /zoos/1 DELETE：删除 123DELETE /zoos/1/employees/2DELETE /zoos/1/employees/2;4;5DELETE /zoos/1/animals //删除id为1的动物园内的所有动物 HEAD / OPTION 用的不多，就不多解释了。 安全性和幂等性 安全性：不会改变资源状态，可以理解为只读的； 幂等性：执行1次和执行N次，对资源状态改变的效果是等价的。 . 安全性 幂等性 GET √ √ POST × × PUT × √ DELETE × √ 安全性和幂等性均不保证反复请求能拿到相同的response。以 DELETE 为例，第一次DELETE返回200表示删除成功，第二次返回404提示资源不存在，这是允许的。 复杂查询查询可以捎带以下参数： . 示例 备注 过滤条件 ?type=1&amp;age=16 允许一定的uri冗余，如/zoos/1与/zoos?id=1 排序 ?sort=age,desc 投影 ?whitelist=id,name,email 分页 ?limit=10&amp;offset=3 Bookmarker经常使用的、复杂的查询标签化，降低维护成本。如： 1GET /trades?status=closed&amp;sort=created,desc 快捷方式： 123GET /trades#recently-closed或者GET /trades/recently-closed Format只用以下常见的3种body format： Content-Type: application/json 12345678910POST /v1/animal HTTP/1.1Host: api.example.orgAccept: application/jsonContent-Type: application/jsonContent-Length: 24&#123; "name": "Gir", "animalType": "12"&#125; Content-Type: application/x-www-form-urlencoded (浏览器POST表单用的格式) 1234567POST /login HTTP/1.1Host: example.comContent-Length: 31Accept: text/htmlContent-Type: application/x-www-form-urlencodedusername=root&amp;password=Zion0101 Content-Type: multipart/form-data; boundary=—-RANDOM_jDMUxq4Ot5 (表单有文件上传时的格式) Content Negotiation资源可以有多种表示方式，如json、xml、pdf、excel等等，客户端可以指定自己期望的格式，通常有两种方式： http header Accept： 1Accept:application/xml;q=0.6,application/atom+xml;q=1.0 q为各项格式的偏好程度 url中加文件后缀：/zoo/1.json Response 不要包装： response 的 body 直接就是数据，不要做多余的包装。错误示例： 1234&#123; "success":true, "data":&#123;"id":1,"name":"xiaotuan"&#125;,&#125; 各HTTP方法成功处理后的数据格式： . response 格式 GET 单个对象、集合 POST 新增成功的对象 PUT/PATCH 更新成功的对象 DELETE 空 json格式的约定： 时间用长整形(毫秒数)，客户端自己按需解析 不传null字段 分页response1234&#123; "paging":&#123;"limit":10,"offset":0,"total":729&#125;, "data":[&#123;&#125;,&#123;&#125;,&#123;&#125;...]&#125; 错误处理 不要发生了错误但给2xx响应，客户端可能会缓存成功的http请求； 正确设置http状态码，不要自定义； Response body 提供 1) 错误的代码（日志/问题追查）；2) 错误的描述文本（展示给用户）。 对第三点的实现稍微多说一点：Java 服务器端一般用异常表示 RESTful API 的错误。API 可能抛出两类异常：业务异常和非业务异常。业务异常由自己的业务代码抛出，表示一个用例的前置条件不满足、业务规则冲突等，比如参数校验不通过、权限校验失败。非业务类异常表示不在预期内的问题，通常由类库、框架抛出，或由于自己的代码逻辑错误导致，比如数据库连接失败、空指针异常、除0错误等等。 业务类异常必须提供2种信息： 如果抛出该类异常，HTTP 响应状态码应该设成什么； 异常的文本描述； 在Controller层使用统一的异常拦截器： 设置 HTTP 响应状态码：对业务类异常，用它指定的 HTTP code；对非业务类异常，统一500； Response Body 的错误码：异常类名 Response Body 的错误描述：对业务类异常，用它指定的错误文本；对非业务类异常，线上可以统一文案如“服务器端错误，请稍后再试”，开发或测试环境中用异常的 stacktrace，服务器端提供该行为的开关。 常用的http状态码及使用场景： 状态码 使用场景 400 bad request 常用在参数校验 401 unauthorized 未经验证的用户，常见于未登录。如果经过验证后依然没权限，应该 403（即 authentication 和 authorization 的区别）。 403 forbidden 无权限 404 not found 资源不存在 500 internal server error 非业务类异常 503 service unavaliable 由容器抛出，自己的代码不要抛这个异常 服务型资源除了资源简单的CRUD，服务器端经常还会提供其他服务，这些服务无法直接用上面提到的URI映射。如： 按关键字搜索； 计算地球上两点间的距离； 批量向用户推送消息 可以把这些服务看成资源，计算的结果是资源的presentation，按服务属性选择合适的HTTP方法。例如： 1234GET /search?q=filter?category=file 搜索GET /distance-calc?lats=47.480&amp;lngs=-122.389&amp;late=37.108&amp;lnge=-122.448POST /batch-publish-msg[&#123;&quot;from&quot;:0,&quot;to&quot;:1,&quot;text&quot;:&quot;abc&quot;&#125;,&#123;&#125;,&#123;&#125;...] 异步任务对耗时的异步任务，服务器端接受客户端传递的参数后，应返回创建成功的任务资源，其中包含了任务的执行状态。客户端可以轮训该任务获得最新的执行进度。 123456789提交任务：POST /batch-publish-msg[&#123;&quot;from&quot;:0,&quot;to&quot;:1,&quot;text&quot;:&quot;abc&quot;&#125;,&#123;&#125;,&#123;&#125;...]返回：&#123;&quot;taskId&quot;:3,&quot;createBy&quot;:&quot;Anonymous&quot;,&quot;status&quot;:&quot;running&quot;&#125;GET /task/3&#123;&quot;taskId&quot;:3,&quot;createBy&quot;:&quot;Anonymous&quot;,&quot;status&quot;:&quot;success&quot;&#125; 如果任务的执行状态包括较多信息，可以把“执行状态”抽象成组合资源，客户端查询该状态资源了解任务的执行情况。 123456789提交任务：POST /batch-publish-msg[&#123;&quot;from&quot;:0,&quot;to&quot;:1,&quot;text&quot;:&quot;abc&quot;&#125;,&#123;&#125;,&#123;&#125;...]返回：&#123;&quot;taskId&quot;:3,&quot;createBy&quot;:&quot;Anonymous&quot;&#125;GET /task/3/status&#123;&quot;progress&quot;:&quot;50%&quot;,&quot;total&quot;:18,&quot;success&quot;:8,&quot;fail&quot;:1&#125; API的演进版本常见的三种方式： 在uri中放版本信息：GET /v1/users/1 Accept Header：Accept: application/json+v1 自定义 Header：X-Api-Version: 1 用第一种，虽然没有那么优雅，但最明显最方便。 URI失效随着系统发展，总有一些API失效或者迁移，对失效的API，返回404 not found 或 410 gone；对迁移的API，返回 301 重定向。 参考&amp;引用转自– Restful API 的设计规范理解RESTful架构RESTful API 设计指南Consumer-Centric API Design 更新时间发布时间 ： 2016-10-29]]></content>
      <tags>
        <tag>Restful API</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[面试] 面试过程中遇到的Cookie和Session的问题]]></title>
    <url>%2F2016%2F10%2F23%2F%E9%9D%A2%E8%AF%95-%E9%9D%A2%E8%AF%95%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84Cookie%E5%92%8CSession%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[主要问题1.说明Cookie和Session这两个概念的联系与区别，解释Session是如何工作的？2.为什么要引入Cookie？Cookie通常存在哪里？关于Cookie存储在哪里，首先要知道Cookie失效分为两种：1.设置过期时间失效（只要设置了过期时间Cookie就会存储在硬盘里面）。2.在会话结束时失效，即关闭浏览器窗口（因为没有设置Expires，Cookie就会存储在内存中）。下面给出一个demo 123456789101112131415161718&lt;div&gt; &lt;button name="btn1" onclick="setCookieBtn1()"&gt;btn1&lt;/button&gt; &lt;button name="btn2" onclick="setCookieBtn2()"&gt;btn2&lt;/button&gt;&lt;/div&gt;&lt;script type="text/javascript" src="/resources/js/jquery-3.1.1.min.js" &gt;&lt;/script&gt;&lt;script type="text/javascript" src="/resources/js/jquery.cookie.js" &gt;&lt;/script&gt;&lt;script type="application/javascript"&gt; function setCookieBtn1()&#123; $.cookie('Memory','Memory'); &#125; function setCookieBtn2()&#123; $.cookie('HardDisk','HardDisk',&#123;expires:1&#125;); &#125;&lt;/script&gt; 依次点击btn1、btn2之后，通过F12调出Chrome的Developer Tools查看Cookie情况 通过Chrome 的 设置-隐私设置 -内容设置-Cookie-所有Cookie和网站数据可以查看结果如下： 重启浏览器之后再次查看结果： 此时名为HardDisk的Cookie存储在 C:\Users\username\AppData\Local\Google\Chrome\User Data\Default中的Cookies文件中。 3.Session对象何时被创建？何时被销毁？1.调用HttpServletRequest.getSession(true)2.Session的销毁 关闭浏览器 设置Session过期 服务器端调用了HttpSession的invalidate()方法。 4.Session通常存在哪里？是否可以持久化？5.Session共享是什么意思？参考&amp;引用更新时间发布时间 ： 2016-10-23]]></content>
      <tags>
        <tag>Session</tag>
        <tag>Cookie</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转载]深入理解web开发中的Session和Cookie]]></title>
    <url>%2F2016%2F10%2F22%2F%E8%BD%AC%E8%BD%BD-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3web%E5%BC%80%E5%8F%91%E4%B8%AD%E7%9A%84Session%E5%92%8CCookie%2F</url>
    <content type="text"><![CDATA[Session 与 Cookie 不管是对 Java Web 的初学者还是熟练使用者来说都是一个令人头疼的问题。在初入职场时恐怕很多程序员在面试的时候都被问到过这个问题。其实这个问题回答起来既简单又复杂，简单是因为它们本身只是 HTTP 协议中的一个配置项，在 Servlet 规范中也只是对应到一个类而已；说它复杂原因在于当我们的系统大到需要用到很多 Cookie 的时候，我们不得不考虑 HTTP 协议对 Cookie 数量和大小的限制，那么如何才能解决这个瓶颈呢？ Session 也会有同样的问题，当我们的一个应用系统有几百台服务器的时候如何解决 Session 在多台服务器之间共享？ Session 与 Cookie 的作用都是为了保持访问用户与后端服务器的交互状态。它们有各自的优点，也有各自的缺陷，然而具有讽刺意味的是它们的优点和它们的使用场景又是矛盾的。例如，使用 Cookie 来传递信息时，随着 Cookie 个数的增多和访问量的增加，它占用的网络带宽也很大，试想假如 Cookie 占用 200 个字节，如果一天的 PV 有几亿，它要占用多少带宽？所以有大访问量的时候希望用 Session，但是 Session 的致命弱点是不容易在多台服务器之间共享，所以这也限制了 Session 的使用。 理解CookieCookie 的作用我想大家都知道，通俗地说就是当一个用户通过 HTTP 协议访问一个服务器的时候，这个服务器会将一些 Key/Value 键值对返回给客户端浏览器，并给这些数据加上一些限制条件，在条件符合时这个用户下次访问这个服务器的时候，数据又被完整地带回给服务器。 这个作用就像您去超市购物时，第一次给您办张购物卡，这个购物卡里存放了一些您的个人信息，下次您再来这个连锁超市时，超市会识别您的购物卡，下次直接购物就好了。 当初 W3C 在设计 Cookie 时实际上考虑的是为了记录用户在一段时间内访问 Web 应用的行为路径。由于 HTTP 协议是一种无状态协议，当用户的一次访问请求结束后，后端服务器就无法知道下一次来访问的还是不是上次访问的用户，在设计应用程序时，我们很容易想到两次访问是同一人访问与不同的两个人访问对程序设计和性能来说有很大的不同。例如，在一个很短的时间内，如果与用户相关的数据被频繁访问，可以针对这个数据做缓存，这样可以大大提高数据的访问性能。Cookie 的作用正是在此，由于是同一个客户端发出的请求，每次发出的请求都会带有第一次访问时服务端设置的信息，这样服务端就可以根据 Cookie 值来划分访问的用户了。 Cookie属性项当前Cookie有两个版本：Version 0和Version 1.通过他们有两种设置响应头的标识，分别是“Set-Cookie”和“Set-Cookie2”。这两个版本的属性项有些不同。 属性项 属性项介绍 NAME=VALUE 键值对，可以设置要保存的 Key/Value，注意这里的 NAME 不能和其他属性项的名字一样 Expires 过期时间，在设置的某个时间点后该 Cookie 就会失效，如 expires=Wednesday, 09-Nov-99 23:12:40 GMT Domain 生成该 Cookie 的域名，如 domain=”xulingbo.net” Path 该 Cookie 是在当前的哪个路径下生成的，如 path=/wp-admin/ Secure 如果设置了这个属性，那么只会在 SSH 连接时才会回传该 Cookie 属性项 属性项介绍 NAME=VALUE 与 Version 0 相同 Version 通过 Set-Cookie2 设置的响应头创建必须符合 RFC2965 规范，如果通过 Set-Cookie 响应头设置，默认值为 0，如果要设置为 1，则该 Cookie 要遵循 RFC 2109 规范 Comment 注释项，用户说明该 Cookie 有何用途 CommentURL 服务器为此 Cookie 提供的 URI 注释 Discard 是否在会话结束后丢弃该 Cookie 项，默认为 fasle Domain 生类似于 Version 0 Max-Age 最大失效时间，与 Version 0 不同的是这里设置的是在多少秒后失效 Port 该 Cookie 在什么端口下可以回传服务端，如果有多个端口，以逗号隔开，如 Port=”80,81,8080” Path 类似于 Version 0 Secure 类似于 Version 0 以上两个版本的 Cookie 中设置的 Header 头的标识符是不同的，我们常用的是 Set-Cookie：userName=“junshan”; Domain=“xulingbo.net”，这是 Version 0 的形式。针对 Set-Cookie2 是这样设置的：Set-Cookie2：userName=“junshan”; Domain=“xulingbo.net”; Max-Age=1000。但是在 Java Web 的 Servlet 规范中并不支持 Set-Cookie2 响应头，在实际应用中 Set-Cookie2 的一些属性项却可以设置在 Set-Cookie 中，如这样设置：Set-Cookie：userName=“junshan”; Version=“1”;Domain=“xulingbo.net”;Max-Age=1000。 Cookie如何工作当我们用如下方式创建Cookie时： 123456789101112131415161718192021222324String getCookie(Cookie[] cookies, String key) &#123; if (cookies != null) &#123; for (Cookie cookie : cookies) &#123; if (cookie.getName().equals(key)) &#123; return cookie.getValue(); &#125; &#125; &#125; return null; &#125; @Override public void doGet(HttpServletRequest request, HttpServletResponse response)throws IOException, ServletException &#123; Cookie[] cookies = request.getCookies(); String userName = getCookie(cookies, "userName"); String userAge = getCookie(cookies, "userAge"); if (userName == null) &#123; response.addCookie(new Cookie("userName", "junshan")); &#125; if (userAge == null) &#123; response.addCookie(new Cookie("userAge", "28")); &#125; response.getHeaders("Set-Cookie"); &#125; Cookie是如何加到HTTP的Header中的呢？当我们用Servlet 3.0规范来创建一个Cookie对象时，该Cookie既支持Version 0又支持Version 1，如果你设置了Version 1中的配置项，即使您没有设置版本号，Tomcat在最后构建HTTP响应头时也会自动将Version的版本设置为1。下面看一下Tomcat是如何调用addCookie方法。 从图中可以看出，真正构建Cookie是在org.apache.catalina.connector.Response类中完成的，调用generateCookieString方法将Cookie对象构建成一个字符串，构造的字符串格式如userName=“junshan”;Version=“1”; Domain=“xulingbo.net”; Max-Age=1000。然后将这个字符串命名为 Set-Cookie 添加到 MimeHeaders 中。 在这里有几点需要注意： 创建的Cookie的NAME不能和Set-Cookie或者Set-Cookie2的属性项值一样，如果一样会抛 IllegalArgumentException异常。 创建Cookie的NAME和VALUE的值不能设置成非ASSIC字符，如果要使用中文，可以通过URLEncoder 将其编码，否则将会抛 IllegalArgumentException 异常。 当 NAME 和 VALUE 的值出现一些 TOKEN 字符（如“\”、“,”等）时，构建返回头会将该 Cookie 的 Version 自动设置为 1。 当该 Cookie 的属性项中出现 Version 为 1 的属性项时，构建 HTTP 响应头同样会将 Version 设置为 1。 不知道您有没有注意一个问题，就是当我们通过response.addCookie创建多个Cookie时，这些Cookie最终是在一个Header项中还是以独立的Header存在的，通俗的说也就是我们每次创建Cookie时是否都是创建一个以NAME为Set-Cookie的MineHeaders？答案是肯定的。从上面的图中可以看出每次调用addCookie的时候，最终都会创建一个Header，但是我们还不知道最终在请求返回时构造HTTP响应头是否将相同Header标识的Set-Cookie值进行合并。 我们找到Tomcat最终构造HTTP响应头的代码，这段代码位于org.apache.coyote.http11. Http11Processor类的prepareResponse 方法中，如下所示： 1234int size = headers.size(); for (int i = 0; i &lt; size; i++) &#123; outputBuffer.sendHeader(headers.getName(i), headers.getValue(i)); &#125; 这段代码清楚地表示，在构建HTTP返回字节流时是将Header终所有的项顺序地写出，而没有进行任何修改。所以可以想象浏览器在接收HTTP协议返回的数据时是分别解析每一个Header项的。 另外，目前很多工具都可以观察甚至可以修改浏览器中的 Cookie 数据。例如，在 Firefox 中可以通过 HttpFox 插件来查看返回的 Cookie 数据，如下图所示。 在 cookie 项中可以详细查看 Cookie 属性项，如下图所示。 前面主要介绍了服务端如何创建 Cookie，下面看一下如何从客户端获取 Cookie。 当我们请求某个 URL 路径时，浏览器会根据这个 URL 路径将符合条件的 Cookie 放在 Request 请求头中传回给服务端，服务端通过 request.getCookies() 来取得所有 Cookie。 使用Cookie的限制Cookie是HTTP协议头中的一个字段，虽然HTTP协议本身对着这个字段并没有多少限制，但是Cookie最终还是存储在浏览器里，所以不同的浏览器对Cookie的存储都有一些限制，下表是一些通常的浏览器对Cookie的大小和数量的限制。 浏览器版本 Cookie数限制 Cookie总大小限制 IE6 20 个 / 每个域名 4095 个字节 IE7 50 个 / 每个域名 4095 个字节 IE8 50 个 / 每个域名 4095 个字节 IE9 50 个 / 每个域名 4095 个字节 Chrome 50 个 / 每个域名 大于 80000 FireFox 50 个 / 每个域名 4095 个字节 理解Session前面介绍了Cookie可以让服务端程序追踪到每个客户端的访问，但是每次客户端的访问都必须传回这些Cookie，如果Cookie很多，这无形地增加了客户端与服务端的数据传输量，而Session的出现正是为了解决这个问题。 同一个客户端每次和服务端交互时，不需要每次都传回所有的Cookie值，而是只要传回一个ID，这个ID是客户端第一次访问服务器的时候生成的，而且每个客户端是唯一的。这样每个客户端就有了一个唯一的ID，客户端只要传回这个ID就行了，这个ID通常是NAME为JSESSIONID的一个Cookie。 Session与Cookie下面详细讲一下Session如何给予Cookie来工作。实际上有三种方式可以让Session正常工作： 基于URL Path Parameter ，默认支持。 基于Cookie，如果没有修改Context容器的cookies标识，默认也是支持的。 基于SSL，默认不支持，只有connector.getAttribute(“SSLEnabled”) 为TRUE时才支持。 第一种情况下，当浏览器不支持Cookie功能时，浏览器会将用户的SessionCookieName重写到用请求的URL参数中，它的传递格式如/path/Servlet;name=value;name2=value2? Name3=value3，其中“Servlet；”后面的K-V就是要传递的Path Parameters，服务器会从这个Path Parameters中拿到用户配置的SessionCookieName。关于这个SessionCookieName，如果在web.xml中配置session-config配置项，其cookie-config下的name属性就是这个SessionCookieName值。如果没有配置session-config配置项，默认的SessionCookieName就是大家熟悉的“JSESSIONID”。需要说明的一点是，与Session关联的Cookie与其他Cookie没有什么不同。接着Request根据这个SessionCookieName倒Parameters中拿到Session ID并设置到request.setRequestedSessionId中。 请注意，如果客户端也支持Cookie，Tomcat仍然会解析Cookie中的Session ID，并会覆盖URL中的Session ID。如果是第三情况，将会根据 javax.servlet.request.ssl_session 属性值设置 Session ID。 Session如何工作有了Session ID服务端就可以创建HttpSession对象了，第一次触发通过request.getSession()方法。如果当前的Session ID还没有对应的HttpSession对象，那么就创建一个新的，并将这个对象加到org.apache.catalina.Manager的sessions容器中保存。Manager类将管理所有Session的生命周期，Session过期将被回收，服务器关闭，Session将被序列化到磁盘等。只要这个HttpSession对象存在，用户就可以根据Session ID来获取这个对象，也就达到了状态的保持。 从上图可以看出，从request.getSession中获取的HttpSession对象实际上是StandardSession对象的门面对象，这与前面的Request和Servlet是一样的原理。 从时序图中可以看到，从Request中获取的Session对象保存在org.apache. catalina.Manager 类中，它的实现类是org.apache.catalina.session.StandardManager，通过requestedSessionId从StandardManager 的sessions集合中取出StandardSession 对象。由于一个requestedSessionId 对应一个访问的客户端，所以一个客户端，也就是对应一个StandardSession 对象，这个对象正式保存我们创建的Session值的。下面我们看一下StandardManager这个类是如何管理StandardSession 的生命周期的。 StandardManager 类负责 Servlet 容器中所有的 StandardSession 对象的生命周期管理。当 Servlet 容器重启或关闭时 StandardManager 负责持久化没有过期的 StandardSession 对象，它会将所有的 StandardSession 对象持久化到一个以“SESSIONS.ser”为文件名的文件中。到 Servlet 容器重启时，也就是 StandardManager 初始化时，会重新读取这个文件解析出所有 Session 对象，重新保存在 StandardManager 的 sessions 集合中。Session 恢复状态图如下图所示。 当 Servlet 容器关闭时 StandardManager 类会调用 unload 方法将 sessions 集合中的 StandardSession 对象写到“SESSIONS.ser”[^1]文件中，然后在启动时再按照上面的状态图重新恢复，注意要持久化保存 Servlet 容器中的 Session 对象，必须调用 Servlet 容器的 stop 和 start 命令，而不能直接结束（kill）Servlet 容器的进程，因为直接结束进程，Servlet 容器没有机会调用 unload 方法来持久化这些 Session 对象。 另外，StandardManager 中的 sessions 集合中的 StandardSession 对象并不是永远保存的，否则 Servlet 容器的内存将很容易被消耗尽，所以必须给每个 Session 对象定义一个有效时间，超过这个时间 Session 对象将被清除。在 Tomcat 中这个有效时间是 60（maxInactiveInterval 属性控制）秒，超过 60 秒该 Session 将会过期。检查每个 Session 是否失效是在 Tomcat 的一个后台线程中完成的（backgroundProcess() 方法中）。过期 Session 状态图如下图所示。 除了后台进程检查 Session 是否失效外，当调用 request.getSession() 时也会检查该 Session 是否过期。值得注意的是，request.getSession() 方法调用的 StandardSession 永远都会存在，即使与这个客户端关联的 Session 对象已经过期。如果过期，又会重新创建一个全新的 StandardSession 对象，但是以前设置的 Session 值将会丢失。如果您取到了 Session 对象但是通过 session.getAttribute 取不到前面设置的 Session 值，请不要奇怪，因为很可能它已经失效了，请检查一下 &lt; Manager pathname=”” maxInactiveInterval=”60” /&gt; 中 maxInactiveInterval 配置项的值，如果不想让 Session 过期可以设置为 -1。但是您要仔细评估一下，网站的访问量和设置的 Session 的大小，防止将您的 Servlet 容器内存撑爆。如果不想自动创建 Session 对象，也可以通过 request.getSession(boolean create) 方法来判断该客户端关联的 Session 对象是否存在。 Cookie安全问题虽然Cookie和Session都可以跟踪客户端的访问记录，但是他们的工作方式显然是不同的，Cookie通过吧所有要保存的数据通过HTTP协议的头部从客户端传递到服务端，又从服务端再传回到客户端，所有的数据都存储在客户端的浏览器里，所以这些Cookie数据可以被访问到，就像我们可以通过Firefox的插件HttpFox查看Cookie，设置可以通过FireCookie插件添加、修改Cookie，所以Cookie的安全性受到了很大的挑战。 相较而言Session的安全性要高很多，因为Session是将数据保存在服务端，只是通过Cookie传递一个SessionID而已，所以Session更适合存储用户隐私和重要的数据。 分布式 Session 框架从前面的分析可知，Session 和 Cookie 各自有优点和缺点。在大型互联网系统中，单独使用 Cookie 和 Session 都是不可行的，原因很简单。因为如果使用 Cookie，可以很好地解决应用的分布式部署问题，大型互联网应用系统一个应用有上百台机器，而且有很多不同的应用系统协同工作，由于 Cookie 是将值存储在客户端的浏览器里，用户每次访问都会将最新的值带回给处理该请求的服务器，所以也就解决了同一个用户的请求可能不在同一台服务器处理而导致的 Cookie 不一致的问题。 存在哪些问题这种“谁家的孩子谁抱走”的处理方式的确是大型互联网的一个比较简单但是的确可以解决问题的处理方式，但是这种处理方式也会带来了很多其他问题，如： 客户端 Cookie 存储限制。随着应用系统的增多 Cookie 数量也快速增加，但浏览器对于用户 Cookie 的存储是有限制的。例如，IE7 之前的 IE 浏览器，Cookie 个数的限制是 20 个，后续的版本，包括 Firefox 等，Cookie 个数的限制都是 50 个。总大小不超过 4KB，超过限制就会出现丢弃 Cookie 的现象发生，这会严重影响应用系统的正常使用。 Cookie 管理的混乱。在大型互联网应用系统中，如果每个应用系统都自己管理每个应用使用的 Cookie，将会导致混乱，由于通常应用系统都在同一个域名下，Cookie 又有上面一条提到的限制，所以没有统一管理很容易出现 Cookie 超出限制的情况。 安全令人担忧。虽然可以通过设置 HttpOnly 属性防止一些私密 Cookie 被客户端访问，但是仍然不能保证 Cookie 无法被篡改。为了保证 Cookie 的私密性通常会对 Cookie 进行加密，但是维护这个加密 Key 也是一件麻烦的事情，无法保证定期来更新加密 Key 也是带来安全性问题的一个重要因素。 当以上问题不能再容忍下去的时候，就不得不想其他办法处理了。 可以解决哪些问题既然 Cookie 有以上这些问题，Session 也有它的好处，为何不结合使用 Session 和 Cookie 呢？下面是分布式 Session 框架可以解决的问题： Session 配置的统一管理。 Cookie 使用的监控和统一规范管理。 Session 存储的多元化。 Session 配置的动态修改。 Session 加密 key 的定期修改。 充分的容灾机制，保持框架的使用稳定性。 Session 各种存储的监控和报警支持。 Session 框架的可扩展性，兼容更多的 session 机制如 wapSession。 跨域名 Session 与 Cookie 如何共享，现在同一个网站可能存在多个域名，如何将 Session 和 Cookie 在不同的域名之间共享是一个具有挑战性的问题。 总体实现思路分布式 Session 框架的架构图如下图所示。 为了达成上面所说的几点目标，我们需要一个服务订阅服务器，在应用启动时可以从这个订阅服务器订阅这个应用需要的可写 Session 项和可写 Cookie 项，这些配置的 Session 和 Cookie 可以限制这个应用能够使用哪些 Session 和 Cookie，甚至可以控制 Session 和 Cookie 可读或者可写。这样可以精确地控制哪些应用可以操作哪些 Session 和 Cookie，可以有效控制 Session 的安全性和 Cookie 的数量。 如 Session 的配置项可以为如下形式： 123456&lt;session&gt; &lt;key&gt;sessionID&lt;/key&gt; &lt;ookiekey&gt;sessionID&lt;/ookiekey &gt; &lt;lifeCycle&gt;9000&lt;/lifeCycle&gt; &lt;base64&gt;true&lt;/base64&gt; &lt;/session &gt; Cookie 的配置可以为如下形式： 123456789&lt;cookie&gt; &lt;key&gt;cookie&lt;/key&gt; &lt;lifeCycle&gt;&lt;/lifeCycle&gt; &lt;type&gt;1&lt;/type&gt; &lt;path&gt;/wp&lt;/path&gt; &lt;domain&gt;xulingbo.net&lt;/ domain&gt; &lt;decrypt&gt;false&lt;/decrypt&gt; &lt;httpOnly&gt;false&lt;/ httpOnly &gt; &lt;/cookie&gt; 统一通过订阅服务器推送配置可以有效地集中管理资源，所以可以省去每个应用都来配置 Cookie，简化 Cookie 的管理。如果应用要使用一个新增 Cookie，可以通过一个统一的平台来申请，申请通过才将这个配置项增加到订阅服务器。如果是一个所有应用都要使用的全局 Cookie，那么只需将这个 Cookie 通过订阅服务器统一推送过去就行了，省去了要在每个应用中手动增加 Cookie 的配置。 关于这个订阅服务器现在有很多开源的配置服务器，如 Zookeeper 集群管理服务器，可以统一管理所有服务器的配置文件。 既然是一个分布式 Session 的处理框架，必然会重新实现 HttpSession 的操作接口，使得应用操作 Session 的对象都是我们实现的 InnerHttpSession 对象，这个操作必须在进入应用之前完成，所以可以配置一个 filter 拦截用户的请求。 先看一下如何封装 HttpSession 对象和拦截请求。 我们可以在应用的 web.xml 中配置一个 SessionFilter，用于在请求到达 MVC 框架之前封装 HttpServletRequest 和 HttpServletResponse 对象，并创建我们自己的 InnerHttpSession 对象，把它设置到 request 和 response 对象中。这样应用系统通过 request.getHttpSession() 返回的就是我们创建的 InnerHttpSession 对象了，我们可以拦截 response 的 addCookies 设置的 Cookie。 在时序图中，应用创建的所有 Session 对象都会保存在 InnerHttpSession 对象中，当用户的这次访问请求完成时，Session 框架将会把这个 InnerHttpSession 的所有内容再更新到分布式缓存中，以便于这个用户通过其他服务器再次访问这个应用系统。另外，为了保证一些应用对 Session 稳定性的特殊要求可以将一些非常关键的 Session 再存储到 Cookie 中，如当分布式缓存存在问题时，可以将部分 Session 存储到 Cookie 中，这样即使分布式缓存出现问题也不会影响关键业务的正常运行。 还有一个非常重要的问题就是如何处理跨域名来共享 Cookie 的问题。我们知道 Cookie 是有域名限制的，也就是一个域名下的 Cookie 不能被另一个域名访问，所以如果在一个域名下已经登录成功，如何访问到另外一个域名的应用且保证登录状态仍然有效，这个问题大型网站应该经常会遇到。如何解决这个问题呢？下面介绍一种处理方式，如下图所示。 从图中可以看出，要实现 Session 同步，需要另外一个跳转应用，这个应用可以被一个或者多个域名访问，它的主要功能是从一个域名下取得 sessionID，然后将这个 sessionID 同步到另外一个域名下。这个 sessionID 其实就是一个 Cookie，相当于我们经常遇到的 JSESSIONID，所以要实现两个域名下的 Session 同步，必须要将同一个 sessionID 作为 Cookie 写到两个域名下。 总共 12 步，一个域名不用登录就取到了另外一个域名下的 Session，当然这中间有些步骤还可以简化，也可以做一些额外的工作，如可以写一些需要的 Cookie，而不仅仅只传一个 sessionID。 除此之外，该框架还能处理 Cookie 被盗取的问题。如您的密码没有丢失，但是您的账号却有可能被别人登录的情况，这种情况很可能就是因为您登录成功后，您的 Cookie 被别人盗取了，盗取您的 Cookie 的人将您的 Cookie 加入到他的浏览器，然后他就可以通过您的 Cookie 正常访问您的个人信息了，这是一个非常严重的问题。在这个框架中我们可以设置一个 Session 签名，当用户登录成功后我们根据用户的私密信息生成的一个签名，以表示当前这个唯一的合法登录状态，然后将这个签名作为一个 Cookie 在当前这个用户的浏览器进程中和服务器传递，用户每次访问服务器都会检查这个签名和从服务端分布式缓存中取得的 Session 重新生成的签名是否一致，如果不一致，显然这个用户的登录状态不合法，服务端将清除这个 sessionID 在分布式缓存中的 Session 信息，让用户重新登录。 Cookie 压缩Cookie 是在 HTTP 的头部，所以通常的 gzip 和 deflate 针对 HTTP Body 的压缩不能压缩 Cookie，如果 Cookie 量非常大，可以考虑将 Cookie 也做压缩，压缩方式是将 Cookie 的多个 k/v 对看成普通的文本，做文本压缩。压缩算法同样可以使用 gzip 和 deflate 算法，但是需要注意的一点是，根据 Cookie 的规范，Cookie 中不能包含控制字符，仅仅只能包含 ASCII 码为（34 ～ 126）的可见字符。所以要将压缩后的结果再进行转码，可以进行 Base32 或者 Base64 编码。 可以配置一个 Filter 在页面输出时对 Cookie 进行全部或者部分压缩，如下代码所示： 12345678910111213141516private void compressCookie(Cookie c, HttpServletResponse res) &#123; try &#123; ByteArrayOutputStream bos = null; bos = new ByteArrayOutputStream(); DeflaterOutputStream dos = new DeflaterOutputStream(bos); dos.write(c.getValue().getBytes()); dos.close(); System.out.println(" before compress length:" + c.getValue(). getBytes().length); String compress = new sun.misc.BASE64Encoder().encode(bos. toByteArray()); res.addCookie(new Cookie("compress", compress)); System.out.println("after compress length:" + compress.getBytes(). length); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 上面的代码是用 DeflaterOutputStream 对 Cookie 进行压缩的，Deflater 压缩后再进行 BASE64 编码，相应地用 InflaterInputStream 进行解压。 123456789101112131415161718private void unCompressCookie(Cookie c) &#123; try &#123; ByteArrayOutputStream out = new ByteArrayOutputStream(); byte[] compress = new sun.misc.BASE64Decoder().decodeBuffer(new String(c.getValue().getBytes())); ByteArrayInputStream bis = new ByteArrayInputStream(compress); InflaterInputStream inflater = new InflaterInputStream(bis); byte[] b = new byte[1024]; int count; while ((count = inflater.read(b)) &gt;= 0) &#123; out.write(b, 0, count); &#125; inflater.close(); System.out.println(out.toByteArray());; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 2KB 大小的 Cookie 压缩前与压缩后字节数相差 20% 左右，如果您的网站的 Cookie 在 2KB~3KB 左右，一天有 1 亿的 PV，那么一天就能够产生 4TB 的带宽流量了，从节省带宽成本来说压缩还是很有必要的。 表单重复提交问题网站中在很多地方都有表单重复提交问题，一种情况是用户在网速慢的情况下可能会重复提交表单，还有就是恶意用户通过程序来发送恶意请求，在这些情况下都要设计一个防止表单重复提交的机制。 要能够防止表单重复提交，就要标识用户的每一次访问请求，使得每一次访问对服务端来说都是唯一确定的。为了标识用户的每次访问请求，可以在用户请求一个表单域时增加一个隐藏表单项，这个表单项的值每次都是唯一的 token，如： 123&lt;form id=”form” method=”post”&gt; &lt;input type=hidden name=“crsf_token” value=“xxxx”/&gt; &lt;/form&gt; 当用户在请求时生成这个唯一的 token 时，同时将这个 token 保存在用户的 Session 中，等用户提交请求时检查这个 token 和当前的 Session 中保存的 token 是否一致。如果一致，说明没有重复提交，否则用户提交上来的 token 已经不是当前的这个请求的合法 token。其工作过程如图所示。 上图是用户发起对表单页面的请求过程，生成唯一的 token 需要一个算法，最简单的就是可以根据一个种子作为 key 生成一个随机数，并保存在 Session 中，等下次用户提交表单时做验证。验证表单的过程如下图所示。 当用户提交表单时会将请求时生成的 token 带回来，这样就可以和 Session 中保存的 token 做对比，从而确认这次表单验证是否合法。 总结Cookie 和 Session 都是为了保持用户访问的连续状态，之所以要保持这种状态，一方面是为了方便业务实现，另一方面就是简化服务端程序设计，提高访问性能，但是这也带来了另外一些挑战，如安全问题、应用的分布式部署带来的 Session 的同步问题及跨域名 Session 的同步等一系列问题。本章分析了 Cookie 和 Session 的工作原理，并介绍了一致分布式 Session 的解决方案。 [^1]: tomcat停止的时候在 /tomcat-6.0.26/work/Catalina/localhost/_/下面生成session.ser文件。文件里面保存了session信息。tomcat启动的时候，从session.ser中读取信息，然后删除session.ser文件。 参考&amp;引用深入理解web开发中的Session和Cookie 更新时间发布时间 ： 2016-10-22]]></content>
      <tags>
        <tag>Session</tag>
        <tag>Cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾对象的判定及垃圾收集算法]]></title>
    <url>%2F2016%2F09%2F17%2F%E5%9E%83%E5%9C%BE%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%A4%E5%AE%9A%E5%8F%8A%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[垃圾对象的判定引用计数算法给对象添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。但是，主流Java虚拟机里面没有选用引用计数法来管理内存，其中最主要的原因是它很难解决对象之间互相循环引用的问题。 可达性分析算法可达性分析算法的基本思想就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain)，当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用。在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的的对象。 方法区中类静态属性引用的对象。 方法去中常量引用的对象。 本地方法栈JNI（即一般说的Native方法）引用的对象。 回收时机可达性分析算法中不可达的对象，也并非是“非死不可”，要真正宣告一个对象的死亡，至少需要经历两次标记过程：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的finalizer线程去执行它。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能导致F-Queue队列中其它对象永久处于等待，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己—只要重新与引用链上的任何一个对象建立关联即可，那它在第二次标记时将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。 垃圾收集算法标记—清除算法最基础的收集算法是“标记—清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段： 首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 该算法的主要不足有两个： 一是效率问题，标记和清除过程的效率都不高 二是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后再程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法为了解决“标记-清除”算法的效率问题，一种称为“复制”(Copying)的收集算法出现了。 “复制”算法将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。现在的商业虚拟机都采用这种收集算法来回收新生代。 标记—整理算法根据老年代的特点，有人提出了一种“标记-整理”（Mark-Compact）算法,同“标记-清除”算法一样，该算法也有“标记“和”整理“两个阶段：首先标记出所有需要回收的对象，让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，根据对象存活周期将内存划分为几块。一般是将Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 新生代在新生代，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。IBM公司的专门研究表明，新生代中的对象98%是“朝生夕死”的，所以将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。当Survivor空间不够用时，需要依赖其它内存（这里指老年代）进行分配担保（Handle Promotion）。 老年代老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或者“标记-整理”算法进行回收 参考&amp;引用《深入理解Java虚拟机》 更新时间发布时间 ： 2016-09-17]]></content>
      <categories>
        <category>《深入理解Java虚拟机》读书笔记</category>
      </categories>
      <tags>
        <tag>垃圾对象的判定</tag>
        <tag>垃圾收集算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存区域与内存溢出异常]]></title>
    <url>%2F2016%2F09%2F10%2FJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[运行时数据区域 程序计数器程序计数器（Program Counter Register）可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令。因此每个线程都需要一个独立的程序计数器，各条线程之间计数器互不硬性，独立存储，我们称这类内存区域为“线程私有”的内存。如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 Java虚拟机栈Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息，每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。经常有人把Java内存区分为堆内存（Heap）和栈内存（Stack），这种分法比较粗糙，其中所说的“栈”就是指虚拟机栈，或者说是虚拟机栈中的局部变量表部分。局部变量表存放了编译器可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 本地方法栈本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本带方法栈则为虚拟机使用到Native方法服务。 Java堆Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配。Java堆是垃圾收集器管理的主要区域，因此很多好时候也被称作“GC堆”（Garbage Collected Heap）。从内存回收的角度来看，由于现在收集器基本都采用分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。从内存分配的角度来看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区。不过无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划分的目的是为了更好地回收内存，或者更快地分配内存。根据Java虚拟机规范的规定，Java堆刻意处于物理上不连续的内存空间中，只要逻辑上是连续的即可。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 方法区方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把它描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开。方法区跟Java堆同样不需要连续的内存和可以选择固定大小或者可拓展外，还可以选择不实现垃圾收集。 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。一般来说，除了保存Class文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。运行时常量池具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区常量池，运行期间也可能将新的常量放入池中。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，肯定还是受到本机总内存（包括RAM和SWAP区或者分页文件）大小以及出来器寻址空间的限制。 内存溢出异常Java堆溢出Java堆用于存储对象实例，只要不断地创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，那么在对象数量到达最大堆的容量限制后就会发生内存溢出异常。要解决这个区域的异常，一般的手段是先通过内存映像分析工具（如Eclipse Memory Analyzer）堆Dump出来的堆砖出快照进行分析，重点是确认内存中的对象是否是必要的，也就是先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）如果是内存泄漏，可通过工具查看对象到GC Roots的引用链。找到泄漏对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收它们。如果是内存溢出，就应当检查虚拟机的堆参数（-Xmx和Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。 虚拟机栈和本地方法栈溢出关于虚拟机栈和本地方法栈，在Java虚拟机规范中描述了两种异常：如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 方法区和运行时常量池溢出对于方法区的测试，基本的思路是运行时产生大量的类去填满方法区，直到溢出。方法区溢出也是一种常见的内存溢出异常，一个类要被垃圾收集器回收掉，判定条件是比较苛刻的。在经常动态生成大量Class的应用中，特别需要注意类的回收状况。这类场景除了上面提到的程序使用了CGLib字节码增强和动态语言之外，常见的还有：大量JSP或动态产生JSP文件、给予OSGi的应用等。 本机直接内存溢出DirectMemory容量可通过-XX：MaxDirectMemorySize指定，如果不指定，则默认与Java堆最大值（-Xmx指定）一样。由DirectMemory导致的内存溢出，一个明显的特征是Heap Dump文件中不会看见明显的异常，如果发现OOM之后Dump文件很小，而程序中又直接或间接使用了NIO，那么就可以考虑检查一下是不是这方面的原因。 参考&amp;引用《深入理解Java虚拟机》 更新时间发布时间 ： 2016-09-10]]></content>
      <categories>
        <category>《深入理解Java虚拟机》读书笔记</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>内存溢出</tag>
        <tag>异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[分享]阿里学习计划]]></title>
    <url>%2F2016%2F09%2F03%2F%E5%88%86%E4%BA%AB-%E9%98%BF%E9%87%8C%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[]]></content>
      <tags>
        <tag>分享</tag>
        <tag>阿里学习计划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Nginx反向代理Tomcat，并实现负载均衡、动静分离]]></title>
    <url>%2F2016%2F08%2F27%2F%E9%85%8D%E7%BD%AENginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86Tomcat%EF%BC%8C%E5%B9%B6%E5%AE%9E%E7%8E%B0%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[前言Nginx与Apache HTTP Server Project（简称Apache）一样，都是开源的HTTP服务器软件，它通常运行在服务器之上，绑定服务器的IP地址并监听某一个tcp端口来接收并处理HTTP请求，这样客户端（一般来说是IE, Firefox，Chrome这样的浏览器）就能够通过HTTP协议来获取服务器上的网页（HTML格式）、文档（PDF格式）、音频（MP4格式）、视频（MOV格式）等等资源。而Tomcat是用来处理java程序的解释器。本身apache也好，nginx也好，都是无法直接处理java语言的，只能通过设置，当收到java文件请求时，传给后方tomcat处理，再把tomcat的反应回给浏览器。 环境JDK ： 1.8.0_101Nginx ： 9.0.0.M9Tomcat ： 1.10.0操作系统 ： ubuntu-16.04（64） 反向代理反向代理什么是反向代理反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。 从上图可以看出：反向代理服务器位于网站机房，代理网站Web服务器接收Http请求，对请求进行转发。 反向代理的作用 保护网站安全：任何来自Internet的请求都必须先经过代理服务器； 通过配置缓存功能加速Web请求：可以缓存真实Web服务器上的某些静态资源，减轻真实Web服务器的负载压力； 实现负载均衡：充当负载均衡服务器均衡地分发请求，平衡集群中各个服务器的负载压力； 配置 在配置之前，如果怕自己在配置过程中出错，可以将需要操作的配置文件进行备份，只需要使用sudo cp -rf fileName fileName-copy 即可备份文件。 Tomcat修改/opt/tomcat9.0/conf目录下的server.xml文件 1234&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps/springmvc&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Context path=&quot;/springmvc&quot; docBase=&quot;springmvc.war&quot;/&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;&lt;/Host&gt; Nginx修改/var/log/nginx目录下的default文件，保证server_name与上面Tomcat配置文件server.xml中的Host name 是一致的。 12345678910111213141516server &#123; #监听端口 listen 80 default_server; listen [::]:80 default_server; #网站程序根目录，一般Nginx和Tomcat在同一个目录 root /opt/tomcat9.0/webapps/springmvc; index index.html index.htm index.nginx-debian.html; #server_name要与Tomcat的server.xml中的Host name一致 server_name localhost; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.182.132:8080; &#125;&#125; Ubuntu下查询本机IP命令 ifconfig -a 测试确认保存好配置文件之后，启动Tomcat和Nginx服务器，在浏览器中输入http://localhost/springmvc/test，会出现以下页面 此时我们可以查看一下Tomcat和Nginx的日志Nginx(/var/log/nginx/access.log) 1127.0.0.1 - - [07/Sep/2016:15:30:47 +0800] &quot;GET /springmvc/test HTTP/1.1&quot; 200 101 &quot;-&quot; &quot;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:48.0) Gecko/20100101 Firefox/48.0&quot; Tomcat(/opt/tomcat9.0/logs/localhost_access_log.xxx.txt) 1192.168.182.132 - - [07/Sep/2016:15:30:47 +0800] &quot;GET /springmvc/test HTTP/1.0&quot; 200 106 负载均衡负载均衡 建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。负载均衡，英文名称为Load Balance，其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务 Nginx支持的负载均衡策略1 round-robinrequests to the application servers are distributed in a round-robin fashion2 least-connectednext request is assigned to the server with the least number of active connections3 ip-hasha hash-function is used to determine what server should be selected for the next request (based on the client’s IP address) 负载均衡的示例12345678910111213141516171819202122232425upstream tomcat &#123; server 192.168.182.132:8080 weight=2; server 192.168.182.132:8081 weight=1; server 192.168.182.132:8082;&#125;server &#123; listen 80 default_server; listen [::]:80 default_server; root /opt/tomcat9.0/webapps/springmvc; index index.html index.htm index.nginx-debian.html; server_name localhost; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://tomcat; &#125;&#125; 动静分离从应用方面讲，Tomcat一般是做动态分析才会用到，支持jsp的解析，而Nginx一般是做静态分析，本身并不具备动态解析功能，需要配置其他插件或者通过其他软件系统才具备动态功能；而在性能方面，不做系统调优的情况下，Tomcat一般支持并发并不高，而Nginx在静态方面支持并发轻松达几万。为了充分利用两者优秀的性能，我们让Tomcat处理用户请求jsp页面实现动态分离，用Nginx处理css、js、html等静态资源，提高性能。 具体实现创建静态资源放置的文件夹将项目中放置静态资源的文件夹拷贝至/opt/springmvc目录下，必须保证各个静态资源的相对路径和在项目中是一致的，否则会出现404错误。 server下配置对应的localtion12345678910111213141516171819202122232425262728293031upstream tomcat &#123; server 192.168.182.132:8080;&#125;server &#123; listen 80 default_server; listen [::]:80 default_server; root /opt/tomcat9.0/webapps/springmvc; index index.html index.htm index.nginx-debian.html; server_name localhost; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://tomcat; &#125; #使用正则表达式拦截后缀名为js、css的静态资源 location ~.*\.(js|css)?$ &#123; #静态资源放置的位置 root /opt; #缓存过期时间 expires 1d; &#125;&#125; 遇到问题1 Tomcat+Nginx实现动静分离的功能，动态请求为什么没有发到Tomcat这里？ 参考&amp;引用nginx documentationNginx搭建反向代理服务器过程详解使用Nginx实现负载均衡tomcat 与 nginx，apache的区别是什么？ 结语写的比较简略，不成章法，接下来会慢慢完善 更新时间发布时间 ： 2016-08-27]]></content>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu系统下安装Nginx服务器的方法]]></title>
    <url>%2F2016%2F08%2F20%2FUbuntu%E7%B3%BB%E7%BB%9F%E4%B8%8B%E5%AE%89%E8%A3%85Nginx%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Nginx简介Nginx是一个非常轻量级的HTTP服务器，Nginx，它的发音为“engine x”，是一个高性能的HTTP和反向代理服务器，同时也是一个IMAP/POP3/SMTP 代理服务器。 Nginx安装系统环境操作系统 ：ubuntu-16.04（64） 在线安装首先因为我并不是项目应用，而且也不是很频繁的使用Linux系统，所以选择更容易上手的Ubuntu系统作为本文Demo的对象。如果选择Debian等Linux系统或者使用源代码安装，在安装Nginx服务器之前需要手动安装依赖的库，但是在Ubuntu系统下，使用在线安装相对来说简单一点。在这里要提醒一下，在线安装和源代码安装的一些命令行和安装位置是不一样的，这个需要具体对待。 使用apt-get在线安装命令： 1$sudo apt-get install nginx 从上图我们可以看出，安装的Nginx的版本是1.10.0。Ubuntu安装Nginx之后的文件结构大致如下表： 文件 路径 配置文件 /etc/nginx 虚拟主机 /etc/nginx/sites-available 启动程序 /usr/sbin/nginx 日志 /var/log/nginx nginx启动脚本 /etc/init.d/ 默认虚拟主机 /usr/share/nginx/www 启动Nginx在线安装的启动过程1$sudo /etc/init.d/nginx start 如果出现[ ok ] Starting nginx (via systemctl): nginx.service.的提示，说明Nginx服务器启动成功，这个时候我们在浏览器中访问一下http://localhost/，正常情况下会出现Nginx的欢迎页面如下图。 常用Nginx命令启动Nginx服务器 1$sudo /etc/init.d/nginx start 关闭Nginx服务器 1sudo service nginx stop 重启Nginx服务器 1sudo service nginx restart 重新加载配置文件 1nginx -s reload 检查配置文件是否出错 1nginx -t Nginx配置主要配置文件通过上面的表格我们知道Nginx的配置文件是/etc/nginx/nginx.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485user www-data;worker_processes auto;pid /run/nginx.pid;events &#123; worker_connections 768; # multi_accept on;&#125;http &#123; ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; gzip_disable &quot;msie6&quot;; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125;#mail &#123;# # See sample authentication script at:# # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript# # # auth_http localhost/auth.php;# # pop3_capabilities &quot;TOP&quot; &quot;USER&quot;;# # imap_capabilities &quot;IMAP4rev1&quot; &quot;UIDPLUS&quot;;# # server &#123;# listen localhost:110;# protocol pop3;# proxy on;# &#125;# # server &#123;# listen localhost:143;# protocol imap;# proxy on;# &#125;#&#125; 其中设置了一些必要的参数，我们发现62行有这样的语句include /etc/nginx/sites-enabled/*.可以看出/etc/nginx/sites-enabled/default文件也是一个核心的配置文件，其中包含了服务器跟目录、服务器名称、location信息和server信息等配置信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586### You should look at the following URL&apos;s in order to grasp a solid understanding# of Nginx configuration files in order to fully unleash the power of Nginx.# http://wiki.nginx.org/Pitfalls# http://wiki.nginx.org/QuickStart# http://wiki.nginx.org/Configuration## Generally, you will want to move this file somewhere, and start with a clean# file but keep this around for reference. Or just disable in sites-enabled.## Please see /usr/share/doc/nginx-doc/examples/ for more detailed examples.### Default server configuration#server &#123; listen 80 default_server; listen [::]:80 default_server; # SSL configuration # # listen 443 ssl default_server; # listen [::]:443 ssl default_server; # # Note: You should disable gzip for SSL traffic. # See: https://bugs.debian.org/773332 # # Read up on ssl_ciphers to ensure a secure configuration. # See: https://bugs.debian.org/765782 # # Self signed certs generated by the ssl-cert package # Don&apos;t use them in a production server! # # include snippets/snakeoil.conf; root /var/www/html; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; server_name _; location / &#123; # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; &#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # include snippets/fastcgi-php.conf; # # # With php7.0-cgi alone: # fastcgi_pass 127.0.0.1:9000; # # With php7.0-fpm: # fastcgi_pass unix:/run/php/php7.0-fpm.sock; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\.ht &#123; # deny all; #&#125;&#125;# Virtual Host configuration for example.com## You can move that to a different file under sites-available/ and symlink that# to sites-enabled/ to enable it.##server &#123;# listen 80;# listen [::]:80;## server_name example.com;## root /var/www/example.com;# index index.html;## location / &#123;# try_files $uri $uri/ =404;# &#125;#&#125; 参考&amp;引用nginx documentationUbuntu中Nginx的安装与配置Ubuntu下安装nginx的步骤分享 更新时间发布时间 ： 2016-08-20]]></content>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下Tomcat部署Web项目]]></title>
    <url>%2F2016%2F08%2F13%2FUbuntu%E4%B8%8BTomcat%E9%83%A8%E7%BD%B2Web%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[环境操作系统 ：ubuntu-16.04（64）JDK ：1.8.0_101Tomcat ：9.0.0.M9 Tomcat下载Tomcat官方网站下载地址，在Ubuntu操作系统上，我们下载zip和tar.gz类型的安装包。 解压将下载到Downloads目录下的 tar.gz文件解压至 /opt目录下 1sudo tar zxvf apache-tomcat-9.0.0.M9.tar.gz -C /opt 为了方便配置，进入/opt目录给文件夹改名（非必须） 1sudo mv apache-tomcat-9.0.0.M9 tomcat9.0 配置进入/opt/tomcat9.0目录，打开启动的脚本文件 12cd /opt/tomcat9.0sudo gedit./bin/startup.sh 打开startup.sh文件后，添加配置信息（注意替换路径） 12345JAVA_HOME=/usr/java/jdk1.8JRE_HOME=$JAVA_HOME/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOMECLASSPATH=.:$JRE_HOME/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarTOMCAT_HOME=/opt/tomcat9.0 查看进入/opt/tomcat9.0目录，启动Tomcat 1sudo ./bin/startup.sh 输出：Using CATALINA_BASE: /opt/tomcat9.0Using CATALINA_HOME: /opt/tomcat9.0Using CATALINA_TMPDIR: /opt/tomcat9.0/tempUsing JRE_HOME: /usr/java/jdk1.8Using CLASSPATH: /opt/tomcat9.0/bin/bootstrap.jar:/opt/tomcat9.0/bin/tomcat-juli.jarTomcat started. 验证tomcat配置和安装是否成功在浏览器中输入：http://localhost:8080/，并访问该网址如果出现以上页面，则说明配置成功。 关闭Tomcat 1sudo ./bin/shutdown.sh 输出：Using CATALINA_BASE: /opt/tomcat9.0Using CATALINA_HOME: /opt/tomcat9.0Using CATALINA_TMPDIR: /opt/tomcat9.0/tempUsing JRE_HOME: /usr/java/jdk1.8Using CLASSPATH: /opt/tomcat9.0/bin/bootstrap.jar:/opt/tomcat9.0/bin/tomcat-juli.jar 此时再次访问http://localhost:8080/页面就会出现 Unable to connect的提示，说明Tomcat被正确关闭。 IDE导出War包暂无 这是我之前导出的一个war包 部署Web项目Tomcat部署Java Web项目有多种方式，此处我们选择war包部署。 war我们将导出的web项目war包拷贝到webapps目录中 位置 ： /opt/tomcat9.0/webapps/springmvc/springmvc.war Tomcat sudo chmod -R 777 fileName 修改文件夹权限 进入/opt/tomcat9.0/conf目录，打开server.xml 12cd /opt/tomcat9.0/confsudo subl server.xml 因为不经常使用Linux操作系统，更不太喜欢vi等编辑器，所以我在Ubuntu下安装了sublime text3 123456789101112131415161718 &lt;Host name="localhost" appBase="webapps/springmvc" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="/springmvc" docBase="springmvc.war"/&gt; &lt;!-- SingleSignOn valve, share authentication between web applications Documentation at: /docs/config/valve.html --&gt; &lt;!-- &lt;Valve className="org.apache.catalina.authenticator.SingleSignOn" /&gt; --&gt; &lt;!-- Access log processes all example. Documentation at: /docs/config/valve.html Note: The pattern used is equivalent to using pattern="common" --&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt;&lt;/Host&gt; appBase代表应用的基础目录，原始默认位置为“webapps”即对应于tomcat根目录下的文件夹webapps；docBase相当于指定的虚拟目录对应的应用程序的绝对路径,是web应用和本地路径;path是tomcat访问这个应用的URL路径。workDir是运行编译成为java二进制代码时候存放的目录。 测试完成配置并保存好server.xml之后，启动Tomcat 1sudo ./bin/startup.sh 在浏览器中输入web项目的访问路径 localhost:8080/springmvc/test 如果出现以上的页面说明部署成功。 后续由于对server.xml文件中的appBase、path以及访问路径还有一些困惑又做了一点实验: 当我如上面的配置启动Tomcat时，webapps/springmvc的目录下的springmvc.war被解压 我尝试修改appBase的内容，进行测试123456789 &lt;Host name="localhost" appBase="webapps/springmvc111" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="/springmvc" docBase="springmvc.war"/&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt;&lt;/Host&gt; 启动Tomcat之后，发现webapps下新生成了一个名为springmvc111的空文件夹 此时在访问localhost:8080/springmvc/test会提示Unable to connect,并且在关闭Tomcat的时候会提示如下信息 我再次尝试修改path的内容，进行测试123456789 &lt;Host name="localhost" appBase="webapps/springmvc" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="/springmvc111" docBase="springmvc.war"/&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt;&lt;/Host&gt; 再次启动Tomcat，webapps/springmvc的目录下的springmvc.war被解压到springmvc111目录中 此时访问localhost:8080/springmvc/test，页面显示正常。 因为我的war包对应的web项目丢失了，而且之后重新做了一个在导出war包这个过程总是会出问题，所以后续的一些测试暂时就不做了。参考&amp;引用更新时间发布时间 ： 2016-08-13]]></content>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16安装JDK1.8]]></title>
    <url>%2F2016%2F08%2F06%2FUbuntu16%E5%AE%89%E8%A3%85JDK1-8%2F</url>
    <content type="text"><![CDATA[环境系统 ： ubuntu-16.04（64） 下载下载之前可通过命令行查看操作系统位数 1getconf LONG_BIT 下载对应的JDK文件 我选择的是jdk-8u101-linux-x64.tar.gz 解压创建目录作为JDK的安装目录，这里选择安装位置为:/usr/java/ 1sudo mkdir /usr/java 将下载到Downloads文件夹中的JDK文件解压到 /usr/java 目录下 12cd Downloads/sudo tar zxvf jdk-8u101-linux-x64.tar.gz -C /usr/java 为了配置环境变量方便，进入/usr/java 目录下给文件夹改名（非必须） 1sudo mv jdk1.8.0_101 jdk1.8 配置环境配置环境1sudo gedit /etc/environment 将内容替换为下面的内容 123PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games$JAVA_HOME/bin&quot;export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/libexport JAVA_HOME=/usr/java/jdk1.8 修改完成后保存并关闭，输入以下命令使环境变量生效 1source /etc/environment 检查配置成果1echo $JAVA_HOME 输出：/usr/java/jdk1.8 1echo $CLASSPATH 输出：.:/usr/java/jdk1.8/lib:/usr/java/jdk1.8/jre/lib:.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib 1echo $PATH 输出：/usr/java/jdk1.8/bin:/usr/java/jdk1.8/jre/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games$JAVA_HOME/bin:/snap/bin 查看安装版本1java -version 输出：java version “1.8.0_101”Java(TM) SE Runtime Environment (build 1.8.0_101-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode) 如果没有起效可尝试重启，毕竟重启治百病 配置所有用户的环境变量，不然重启之后依然找不到Java命令1sudo gedit /etc/profile 在尾部添加一下内容即可（注意替换路径）： 12345#set Java environmentJAVA_HOME=/usr/java/jdk1.8export JRE_HOME=/usr/java/jdk1.8/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 完成参考&amp;引用Ubuntu 15.04 安装JDK并配置成为默认的JDK 更新时间发布时间 ： 2016-08-06]]></content>
      <tags>
        <tag>Ubuntu</tag>
        <tag>JDK1.8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu系统安装使用Sublime Text3]]></title>
    <url>%2F2016%2F08%2F06%2FUbuntu%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8Sublime-Text3%2F</url>
    <content type="text"><![CDATA[环境准备 Ubuntu 16.04 Sublime Text 3 Sublime Text 3安装步骤添加Sublime Text 3软件包的软件源sudo add-apt-repository ppa:webupd8team/sublime-text-3 使用以下命令更新系统软件源sudo apt-get update 使用以下命令安装Sublime Text 3sudo apt-get install sublime-text-installer 等待Sublime安装成功，就可以通过subl命令调用了。 参考&amp;引用更新时间发布时间 ： 2016-08-06]]></content>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Sublime Text3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA创建Maven多模块项目]]></title>
    <url>%2F2016%2F07%2F23%2FIntelliJ-IDEA%E5%88%9B%E5%BB%BAMaven%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[项目结构首先放上一张项目构建完之后的图 通过上图可知，父项目（ShzThink）聚合很多子项目（common-utils、common-dao、common-service、think-web、think-crm）。这些模块的依赖关系如下：common-dao –&gt; common-utilscommon-service –&gt; common-daothink-web –&gt; common-servicethink-crm –&gt; common-service 项目构建Parent Project新建一个空白标准maven project（不要选择Create from archetype选项） 得到一个标准的maven项目，因为该项目是作为一个Parent project存在的，可以直接删除src文件夹。 增加common-*模块 选中父模块之后，依次New-&gt;Module,会出现下面窗口，勾选Create from archetype，选择maven-archetype-quickstart选项。 以此方法依次创建common-utils、common-dao、common-service子模块。 增加think-*模块与2.2中相似，只不过因为think-*是我们最终要部署的应用，因此在创建模块的时候选择maven-archetype-webapp选项。 添加项目依赖以common-dao模块为例，在添加依赖之前，我们可以看到它的pom文件是这样的： &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;shz-think-backend&lt;/artifactId&gt; &lt;groupId&gt;com.shzthink.web&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;common-dao&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;common-dao&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 选择common-dao子模块，右键-&gt;Open Module Settings,出现如下窗口，选择common-utils。 此时再查看common-dao子模块的pom文件会发现在 &lt; dependencies&gt;下增加了一段代码： &lt;dependency&gt; &lt;groupId&gt;com.shzthink.web&lt;/groupId&gt; &lt;artifactId&gt;common-utils&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; 依照上述方法依次给common-service、think-web、think-crm添加依赖。此时就完成了多模块Maven项目的创建。 Build项目在ShzThink父项目的根目录中运行mvn clean install，输出的末尾大概会是这样的 注意Reactor Summary，整个项目根据我们希望的顺序进行build。Maven根据我们的依赖配置，智能的安排了顺序。 参考&amp;引用Maven最佳实践 划分模块 配置多模块项目 pom modules 更新时间发布时间 ： 2016-07-23]]></content>
      <tags>
        <tag>IntelliJ IDEA</tag>
        <tag>Maven</tag>
        <tag>多模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Spring MVC菜鸟之旅] Spring MVC 与 MyBatis整合]]></title>
    <url>%2F2016%2F07%2F16%2FSpring-MVC%E8%8F%9C%E9%B8%9F%E4%B9%8B%E6%97%85-Spring-MVC-%E4%B8%8E-MyBatis%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[MyBatisMyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 整合MyBatis-Spring 会帮助你将 MyBatis 代码无缝地整合到 Spring 中。 使用这个类库中的类, Spring 将会加载必要的 MyBatis 工厂类和 session 类。 这个类库也提供一个简单的方式来注入 MyBatis 数据映射器和 SqlSession 到业务层的 bean 中。 而且它也会处理事务, 翻译 MyBatis 的异常到 Spring 的 DataAccessException 异常中。最终,它并 不会依赖于 MyBatis,Spring 或 MyBatis-Spring 来构建应用程序代码。 安装要使用MyBatis，并且使用Maven来构建项目，则只需将下面的dependency代码置于pom.xml文件中： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt;&lt;/dependency&gt; 要和Spring一起使用MyBatis，我们需要在SPring应用上下文中定义至少两样东西：一个SqlSessionFactory 和至少一个数据映射器类。 从XML中构建SqlSessionFactory在 MyBatis-Spring中,SqlSessionFactoryBean 是用于创建SqlSessionFactory的。要配置这个工厂bean,放置下面的代码在 Spring的XML配置文件中: 123&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource" /&gt;&lt;/bean&gt; 要注意SqlSessionFactoryBean需要一个DataSource（数据源）。这可以是任意的DataSource，配置它就像配置其他的Spring数据库连接是一样的。 123456&lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt;&lt;/bean&gt; 创建数据映射器类我们创建的数据映射器类如下： 1234public interface TestMapper &#123; @Select("SELECT * From auth_user WHERE id = #&#123;id&#125;") Test getTest(@Param("id") long id);&#125; 然后用MapperFactoryBean将给接口加入到Spring中： 1234&lt;bean id="testMapper" class="org.mybatis.spring.mapper.MapperFactoryBean"&gt; &lt;property name="mapperInterface" value="com.springmvc.niklaus.dao.TestMapper" /&gt; &lt;property name="sqlSessionFactory" ref="sqlSessionFactory" /&gt;&lt;/bean&gt; 注意所指定的映射器类必须是一个接口而不是具体的实现类。在这个实例中，注解被用来指定SQL语句，但是MyBatis的映射器XML文件也可以用，这个我将在下面再讲。 事务一个使用MyBatis-Spring的主要原因是它允许MyBatis参与到Spring的事务管理中，而不是给MyBatis创建一个新的特定的事务管理器。 12345&lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt;&lt;/bean&gt;&lt;tx:annotation-driven transaction-manager="transactionManager" /&gt; 要开始Spring的事务管理，要在Spring的XML配置文件中创建一个DataSourceTransactionManager对象，然后使用指定transactionManager作为事务管理器，支持事务注解（@Transactional），此时在需要事务管理的Service上使用@Transactional注解就可以了，只会查找和它在相同的应用上下文件中定义的bean上面的@Transactional注解。 123456789101112@Service@Transactionalpublic class TestServiceImpl implements TestService&#123; @Autowired private TestMapper testMapper; public Test getTestById(long id) &#123; return testMapper.getTest(id); &#125;&#125; 结语先附上完整的MyBatis的配置XML文件spring-db.xml 123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt; &lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;/bean&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;bean id="testMapper" class="org.mybatis.spring.mapper.MapperFactoryBean"&gt; &lt;property name="mapperInterface" value="com.springmvc.niklaus.dao.TestMapper" /&gt; &lt;property name="sqlSessionFactory" ref="sqlSessionFactory" /&gt; &lt;/bean&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;tx:annotation-driven transaction-manager="transactionManager" /&gt;&lt;/beans&gt; 这样，一个满足基本增删改查的Spring与MyBatis的整合应用就完成了，如果你想查看完整的项目代码，可以点击链接(SpringMVCRookie-dev-mybatis) 参考&amp;引用mybatismybatis-spring 更新时间发布时间 ： 2016-07-16]]></content>
      <categories>
        <category>Spring MVC菜鸟之旅</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[[Spring MVC菜鸟之旅] Spring Data Redis整合]]></title>
    <url>%2F2016%2F07%2F09%2FSpring-MVC%E8%8F%9C%E9%B8%9F%E4%B9%8B%E6%97%85-Spring-Data-Redis%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[The Spring Framework is the leading full-stack Java/JEE application framework. It provides a lightweight container and a non-invasive programming model enabled by the use of dependency injection, AOP, and portable service abstractions.NoSQL storages provide an alternative to classical RDBMS for horizontal scalability and speed. In terms of implementation, Key Value stores represent one of the largest (and oldest) members in the NoSQL space.The Spring Data Redis (or SDR) framework makes it easy to write Spring applications that use the Redis key value store by eliminating the redundant tasks and boiler plate code required for interacting with the store through Spring’s excellent infrastructure support. Redis使用Redis 此处简单介绍一下Linux下得Redis安装，windows比较麻烦没有尝试 下载、解压并编译Redis文件1234$ wget http://download.redis.io/releases/redis-3.2.4.tar.gz$ tar xzf redis-3.2.4.tar.gz$ cd redis-3.2.4$ make 运行redis-server1$ sudo ./src/redis-server 启动Redis客户端1$ sudo ./src/redis-cli Redis 数据类型Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。 String（字符串）string是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。string类型是Redis最基本的数据类型，一个键最大能存储512MB。 12345127.0.0.1:6379&gt; set name &quot;runoob&quot;OK127.0.0.1:6379&gt; get name&quot;runoob&quot;127.0.0.1:6379&gt; Hash（哈希）Redis hash 是一个键值对集合。Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 123456789127.0.0.1:6379&gt; hmset user:1 username runoob password runoob points 200OK127.0.0.1:6379&gt; hgetall user:11) &quot;username&quot;2) &quot;runoob&quot;3) &quot;password&quot;4) &quot;runoob&quot;5) &quot;points&quot;6) &quot;200&quot; 以上实例中 hash 数据类型存储了包含用户脚本信息的用户对象。 实例中我们使用了 Redis HMSET, HGETALL 命令，user:1 为键值。每个 hash 可以存储 232 -1 键值对（40多亿）。 List（列表）Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 12345678910127.0.0.1:6379&gt; lpush runoob redis(integer) 1127.0.0.1:6379&gt; lpush runoob mongodb(integer) 2127.0.0.1:6379&gt; lpush runoob rabitmq(integer) 3127.0.0.1:6379&gt; lrange runoob 0 101) &quot;rabitmq&quot;2) &quot;mongodb&quot;3) &quot;redis&quot; 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。 Set（集合）Redis的Set是string类型的无序集合。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 sadd命令添加一个string元素到,key对应的set集合中，成功返回1,如果元素已经在集合中返回0,key对应的set不存在返回错误。 1sadd key member 123456789101112127.0.0.1:6379&gt; sadd runoobs redis(integer) 1127.0.0.1:6379&gt; sadd runoobs mongodb(integer) 1127.0.0.1:6379&gt; sadd runoobs rabitmq(integer) 1127.0.0.1:6379&gt; sadd runoobs rabitmq(integer) 0127.0.0.1:6379&gt; smembers runoobs1) &quot;rabitmq&quot;2) &quot;mongodb&quot;3) &quot;redis&quot; 注意：以上实例中 rabitmq 添加了两次，但根据集合内元素的唯一性，第二次插入的元素将被忽略。集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。 zset(sorted set : 有序集合)Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。 zadd命令添加元素到集合，元素在集合中存在则更新对应score 1zadd key score member 123456789101112127.0.0.1:6379&gt; zadd runoobz 0 redis(integer) 1127.0.0.1:6379&gt; zadd runoobz 0 mongodb(integer) 1127.0.0.1:6379&gt; zadd runoobz 0 rabitmaq(integer) 1127.0.0.1:6379&gt; zadd runoobz 0 rabitmaq(integer) 0127.0.0.1:6379&gt; zrangebyscore runoobz 0 101) &quot;mongodb&quot;2) &quot;rabitmaq&quot;3) &quot;redis&quot; 整合Spring Data RedisSpring Redis要求Redis的版本不低于2.6，Java SE版本不低于6.0，在语言绑定（连接器）方面，Spring Redis集成了Jedis，JRedis，SRP和Lettuce四个流行的Redis方面的Java库。 添加相关文件123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.7.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置RedisConnectionFactory1234567891011121314&lt;bean id="poolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="$&#123;redis.maxIdle&#125;" /&gt; &lt;property name="maxTotal" value="$&#123;redis.maxTotal&#125;" /&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.maxWaitMillis&#125;" /&gt;&lt;/bean&gt;&lt;!-- Jedis ConnectionFactory --&gt;&lt;bean id="jedisConnectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;property name="hostName" value="$&#123;redis.hostname&#125;" /&gt; &lt;property name="port" value="$&#123;redis.port&#125;" /&gt; &lt;property name="timeout" value="$&#123;redis.timeout&#125;" /&gt; &lt;property name="usePool" value="true" /&gt; &lt;property name="poolConfig" ref="poolConfig" /&gt;&lt;/bean&gt; 通过RedisTemplate使用对象Most users are likely to use RedisTemplate and its coresponding package org.springframework.data.redis.core - the template is in fact the central class of the Redis module due to its rich feature set. The template offers a high-level abstraction for Redis interactions. While RedisConnection offers low level methods that accept and return binary values (byte arrays), the template takes care of serialization and connection management, freeing the user from dealing with such details. 1234567891011&lt;!-- Serializer --&gt;&lt;!-- 如果不配置Serializer，那么存储的时候只能使用String，如果存储其他类型的对象，将会提示错误--&gt;&lt;bean id="keySerializer" class="org.springframework.data.redis.serializer.StringRedisSerializer" /&gt;&lt;bean id="valueSerializer" class="org.springframework.data.redis.serializer.StringRedisSerializer" /&gt;&lt;!-- redis template definition --&gt;&lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate"&gt; &lt;property name="connectionFactory" ref="jedisConnectionFactory" /&gt; &lt;property name="keySerializer" ref="keySerializer"/&gt; &lt;property name="valueSerializer" ref="valueSerializer"/&gt;&lt;/bean&gt; RedisTemplate uses a Java-based serializer for most of its operations. This means that any object written or read by the template will be serialized/deserialized through Java. The serialization mechanism can be easily changed on the template, and the Redis module offers several implementations available in the org.springframework.data.redis.serializer package - see Serializers for more information. You can also set any of the serializers to null and use RedisTemplate with raw byte arrays by setting the enableDefaultSerializer property to false. Note that the template requires all keys to be non-null - values can be null as long as the underlying serializer accepts them; read the javadoc of each serializer for more information. 1234567891011121314151617package com.springmvc.niklaus.dao.Impl;@Repositorypublic class TestDAOImpl implements TestDAO&#123; @Resource private RedisTemplate&lt;String,String&gt; redisTemplate; public void rSave(String key,String value)&#123; redisTemplate.opsForValue().set(key,value); &#125; public String rGet(String key)&#123; return redisTemplate.opsForValue().get(key); &#125;&#125; 参考&amp;引用RedisSpring Data RedisSpring Data Redis - APISpring Data Redis - Projects 更新时间发布时间 ： 2016-07-09]]></content>
      <categories>
        <category>Spring MVC菜鸟之旅</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[[Spring MVC菜鸟之旅] 通过配置文件分析Spring MVC与Hibernate的整合]]></title>
    <url>%2F2016%2F07%2F03%2FSpring-MVC%E8%8F%9C%E9%B8%9F%E4%B9%8B%E6%97%85-%E9%80%9A%E8%BF%87%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90Spring-MVC%E4%B8%8EHibernate%E7%9A%84%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[前言当使用Spring开发持久层的时候，我们会面临多种选择。我们可以使用JDBC、Hibernate、MyBatis或其他任意的持久化框架。在这里简单介绍一下使用Hibernate作为持久化框架。 Spring的数据访问哲学Spring的目标之一就是允许开发人员在开发应用程序时，能够遵循面向对象（OO）原则中的“针对接口编程”。Spring对数据访问的支持也不例外。DAO是数据访问对象（data access object）的缩写。DAO提供了数据读取和写入到数据库中的一种方式。它们应该以接口的方式发布功能，而应用程序的其他部分就可以通过接口来进行访问。下图展现了设计数据访问层的合理方式。 如上图所示，服务对象通过接口来访问DAO。这样的好处有:(1) 服务对象易于测试，因为它们不再与特定的数据访问实现绑定在一起。(2) 数据访问层是以持久化技术无关的方式来进行访问。持久化方式的选择独立于DAO，只要相关的数据访问方法通过接口来进行发布。这可以实现灵活的设计并使得切换持久化框架对应用程序其他部分所带来的影响最小。如果将数据层的实现细节渗透到应用程序的其他部分中，那么整个应用程序将于数据访问层耦合在一起，从而导致僵化的设计。 配置数据源Spring提供了在Spring上下文中配置数据源Bean的多种方式，包括：(1) 通过JDBC驱动程序定义的数据源；(2) 通过JNDI查找的数据源；(3) 连接池的数据源对于即将发布到生产环境中的应用程序，我建议使用从连接池获取连接的数据源。我们把所有有关于Hibernate的配置都放置在resource目录下spring-db.xml的文件上 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!-- 配置数据源 --&gt;&lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource" destroy-method="close"&gt; &lt;property name="driverClass" value="com.mysql.jdbc.Driver" /&gt; &lt;property name="jdbcUrl"&gt; &lt;value&gt;$&#123;jdbc.url&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="user"&gt; &lt;value&gt;$&#123;jdbc.username&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="password"&gt; &lt;value&gt;$&#123;jdbc.password&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="minPoolSize"&gt; &lt;value&gt;$&#123;jdbc.pool.min&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="maxPoolSize"&gt; &lt;value&gt;$&#123;jdbc.pool.max&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="initialPoolSize"&gt; &lt;value&gt;$&#123;jdbc.pool.init&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="maxStatements"&gt; &lt;value&gt;$&#123;jdbc.pool.maxStatements&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="maxIdleTime"&gt; &lt;value&gt;$&#123;jdbc.pool.maxIdleTime&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="idleConnectionTestPeriod"&gt; &lt;value&gt;$&#123;jdbc.pool.idleConnectionTestPeriod&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="acquireRetryAttempts"&gt; &lt;value&gt;$&#123;jdbc.pool.acquireRetryAttempts&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="breakAfterAcquireFailure"&gt; &lt;value&gt;$&#123;jdbc.pool.breakAfterAcquireFailure&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="testConnectionOnCheckout"&gt; &lt;value&gt;$&#123;jdbc.pool.testConnectionOnCheckout&#125;&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 在Spring中集成Hibernate声明Hibernate的Session工厂以前，在Spring应用程序中使用的Hibernate是通过HibernateTemplate进行的，它简化了Hibernate的繁琐工作，它的职责之一是管理Hibernate的Session。这涉及打开和关闭Session并确保每个事务使用相同的Session。HibernateTemplate的不足之处在于存在一定程度的侵入性。但我们在DAO中使用HibernateTemplate（不管直接使用还是通过HibernateDaoSupport）时，DAO类都会与SpringAPI产生耦合。 Hibernate3引入了上下文Session（Contextual session），这是Hibernate本身所提供的保证每个事务使用同一Session的方案。这种方式能够让你的DAO类不包含特定的Spring代码。我在《[Spring MVC菜鸟之旅] Spring MVC 与 Hibernate整合》中就是使用HibernateTemplate，但鉴于上下文Session是使用Hibernate的最佳实践，所以下面的介绍将只关注上下文Session。 使用Hibernate的主要接口实org.hibernate.Session。Session接口提供了基本的数据访问功能，通过Hibernate的Session接口，应用程序的DAO能够满足所有的持久化需求。 获取Hibernate Session对象的标准方式是借助Hibernate的SessionFactory接口的实现类。除了一些其他的任务，SessionFactory主要负责Hibernate Session的打开。关闭以及管理。 在Spring中我们通过SPring的某一个Hibernate Session工厂Bean来获取Hibernate的SessionFactory。我们可以在应用程序的Spring上下文中，像配置其他Bean那样来配置Hibernate Session工厂。在配置Hibernate Session工厂的Bean的时候，我们一般在持久化域对象是通过XML来进行配置的。当选在XML中定义对象与数据库之间的映射，需要在Spring中配置LocalSessionFactoryBean（若更倾向使用注解的方式来定义持久化的话，需要使用AnnotationSessionFactoryBean配置） 1234567891011121314151617&lt;bean id="sessionFactory" class="org.springframework.orm.hibernate4.LocalSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;property name="hibernateProperties"&gt; &lt;props&gt; &lt;prop key="hibernate.dialect"&gt; org.hibernate.dialect.MySQLDialect &lt;/prop&gt; &lt;prop key="hibernate.show_sql"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.hbm2ddl.auto"&gt;none&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;property name="packagesToScan"&gt; &lt;list&gt; &lt;value&gt;com.niklaus.springmvc.pojo&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 使用packagesToScan属性告诉Spring扫描一个或多个包以查找域类，这些类通过注解方式来表明要使用Hibernate进行持久化。 12345&lt;property name="packagesToScan"&gt; &lt;list&gt; &lt;value&gt;com.niklaus.springmvc.pojo&lt;/value&gt; &lt;/list&gt;&lt;/property&gt; 因为我只需要扫描一个包，所以我使用了一个内部的属性编辑器将单个的String自动转换为String数组。 构建不依赖于Spring的Hibernate代码在Spring应用上下文中配置Hibernate Session工厂Bean后，可以准备创建自己的DAO类了。 12345678910111213141516171819202122232425262728293031323334@Repositorypublic class TestDAOImpl implements TestDAO&#123; private SessionFactory sessionFactory; //构造DAO @Autowired public TestDAOImpl(SessionFactory sessionFactory)&#123; this.sessionFactory = sessionFactory; &#125; public void addTest(Test test) &#123; Session session = sessionFactory.openSession(); Transaction tx = session.beginTransaction(); session.save(test); tx.commit(); session.close(); &#125; public Test getTestById(long id) &#123; Session session = sessionFactory.openSession(); Test test = (Test) session.get(Test.class,id); session.close(); return test; &#125; public void updateTest(Test test) &#123; Session session = sessionFactory.openSession(); Transaction tx = session.beginTransaction(); session.update(test); tx.commit(); session.close(); &#125;&#125; 事务管理在软件开发领域，全有或全无的操作被称为事务（transaction）。事务允许你讲几个操作组合成一个要么全部发生要么全部不发生的工作单元。如果一切顺利，事务将会成功。但是有任何一件事情出错的话，所发生的行为将会被清除干净，就像什么事情都没有发生一样。 事务特性（ACID）原子性（Atomic）事务是由一个或多个活动所组成的一个工作单元。原子性确保食物中的所有操作全部发生或者全部不发生。如果所有活动都成功了，事务也就成功了。如果任意一个活动失败了，整个事务也失败并回滚。 一致性（Consistent）一旦事务完成（不管成功还是失败），系统必须确保它所建模的业务处于一致的状态。现实的数据不应该被损坏。 隔离性（Isolated）事务允许多个用户对相同的数据进行操作，每个用户的操作不会与其他用户纠缠在一起。因此，事务应该被彼此隔离，避免发生同步读写相同数据的事情（注意的是，隔离性往往涉及到锁定数据库中的行或表）。 持久性（Durable）一旦事务完成，事务的结果应该持久化，这样就能从任何的系统崩溃中会发过来。这一般会设计将结果存储到数据库或者其他形式的持久化存储中。 使用Hibernate事务管理器如果应用程序的持久化是通过Hibernate实现的，那么久需要使用HibernateTransactionManager。需要在Spring上下文定义中添加如下的声明： 123&lt;bean id="transactionManager" class="org.springframework.orm.hibernate4.HibernateTransactionManager"&gt; &lt;property name="sessionFactory" ref="sessionFactory" /&gt;&lt;/bean&gt; HibernateTransactionManager将事务管理的职责委托给org.hibernate.Transaction对象，而后者是从Hibernate Session中获取到的。当事务成功完成时，HibernateTransactionManager将会调用Transaction对象的commit()方法。类似地，如果事务失败，Transaction对象的rollback()方法将会被调用。 声明式事务在XML中定义事务Spring为POJO提供了声明式事务的支持，它是通过Spring AOP框架实现的。Spring提供了3种方式来声明事务式边界，包括Spring AOP和TransactionProxyFactory的代理Bean来实现声明式事务，但自从Spring 2.0，声明事务的更好方式是使用Spring的tx命名空间和@Transactional注解。使用tx命名空间会涉及将其添加到Spring XML配置文件中： 12345678&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; 要注意的是，aop命名空间也应该包括在内。这是很重要的，因为有一些声明式事务配置元素依赖于部分Spring的AOP配置元素。 1234567&lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;!-- 定义方法的过滤规则 --&gt; &lt;tx:attributes&gt; &lt;!-- 所有方法都使用事务 --&gt; &lt;tx:method name="*" propagation="REQUIRED" /&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 当使用来声明事务时，还需要一个事务管理器。根据约定优于配置，假定事务管理器被声明为一个id为transactionManager的Bean。如果碰巧为事务管理配置器配置了一个不同的id，则需要在transactionmanager属性中明确指定事务管理器的id。 只是定义了AOP通知，用于吧事务边界通知给方法。但是这只是事务通知，而不是完整的事务性切面。我们在中没有声明哪些Bean应该被通知—我们需要一个切点来做这件事。为了完整定义事务性切面，我们必须定义一个通知器（advisor）。 12345&lt;aop:config&gt; &lt;!-- 定义一个切入点 --&gt; &lt;aop:pointcut id="services" expression="execution (* com.springmvc.niklaus.service.*Service.*(..))" /&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="services" /&gt;&lt;/aop:config&gt; 这里的pointcut属性使用了AspectJ切入点表达式来表明通知器适用于哪些方法。哪些方法应该真正运行在事务中以及方法的事务属性都是由这个事务通知来定义的，而事务通知是advice-ref属性来制定的，它引用了名为txAdvice的通知。 定义注解驱动的事务除了元素，tx命名空间还提供了元素，使用时，通常只需要一行XML： 1&lt;tx:annotation-driven transaction-manager="transactionManager"/&gt; 通过transaction-manager属性（默认值为transactionManager）来制定特定的事务管理器。 元素告诉Spring检索上下文中所有的Bean并查找使用@Transactional注解的Bean，而不管这个注解使用在类级别上还是方法级别上。对于每一个使用@Transactional注解的Bean，都会自动为它添加事务通知。通知的事务属性是通过@Transactional注解的参数来定义的。 小结github地址 SpringMVCRookie 参考&amp;引用《spring实战(第三版)》 更新时间发布时间 ： 2016-07-03]]></content>
      <categories>
        <category>Spring MVC菜鸟之旅</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[[Spring MVC菜鸟之旅] Spring MVC 与 Hibernate整合]]></title>
    <url>%2F2016%2F07%2F02%2FSpring-MVC%E8%8F%9C%E9%B8%9F%E4%B9%8B%E6%97%85-Spring-MVC-%E4%B8%8E-Hibernate%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[应用结构先贴上一张本文最终运行成功的Spring MVC程序的结构图 配置项目使用Maven导入SpringMVC所依赖的包，修改pom.xml文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation=" http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.nicklaus.springmvc&lt;/groupId&gt; &lt;artifactId&gt;springmvc&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;springmvc Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;spring.version&gt;4.3.0.RELEASE&lt;/spring.version&gt; &lt;hibernate.version&gt;4.3.11.Final&lt;/hibernate.version&gt; &lt;mysql.version&gt;5.1.29&lt;/mysql.version&gt; &lt;c3p0.version&gt;0.9.1.2&lt;/c3p0.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- Spring start --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring end --&gt; &lt;!--hibernate--&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;$&#123;hibernate.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--数据库连接池C3P0--&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;$&#123;c3p0.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- jstl for jsp page --&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;springmvc&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.2.1.v20140609&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 修改WEB-INF下的web.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"&gt; &lt;display-name&gt;SpringMVCDemo&lt;/display-name&gt; &lt;!-- 配置spring应用上下文 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:applicationContext.xml &lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置spring核心servlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:dispatcher-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 保持之前dispatcher-servlet.xml内容不变12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd "&gt; &lt;!-- 处理静态资源 --&gt; &lt;mvc:resources location="resources" mapping="/resources/**"/&gt; &lt;!-- 启动注解驱动的Spring MVC功能，注册请求url和注解POJO类方法的映射--&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- 启动包扫描功能，以便注册带有@Controller、@Service、@repository、@Component等注解的类成为spring的bean --&gt; &lt;context:component-scan base-package="com.niklaus.springmvc" /&gt; &lt;!-- 对模型视图名称的解析，在请求时模型视图名称添加前后缀 --&gt; &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/views/" /&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;/bean&gt;&lt;/beans&gt; 在resource目录下创建applicationContext.xml文件123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;value&gt;classpath:dev/config.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;import resource="spring-db.xml" /&gt;&lt;/beans&gt; 在resource目录下创建spring-db.xml文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource" destroy-method="close"&gt; &lt;property name="driverClass" value="com.mysql.jdbc.Driver" /&gt; &lt;property name="jdbcUrl"&gt; &lt;value&gt;$&#123;jdbc.url&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="user"&gt; &lt;value&gt;$&#123;jdbc.username&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="password"&gt; &lt;value&gt;$&#123;jdbc.password&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="minPoolSize"&gt; &lt;value&gt;$&#123;jdbc.pool.min&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="maxPoolSize"&gt; &lt;value&gt;$&#123;jdbc.pool.max&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="initialPoolSize"&gt; &lt;value&gt;$&#123;jdbc.pool.init&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="maxStatements"&gt; &lt;value&gt;$&#123;jdbc.pool.maxStatements&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="maxIdleTime"&gt; &lt;value&gt;$&#123;jdbc.pool.maxIdleTime&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="idleConnectionTestPeriod"&gt; &lt;value&gt;$&#123;jdbc.pool.idleConnectionTestPeriod&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="acquireRetryAttempts"&gt; &lt;value&gt;$&#123;jdbc.pool.acquireRetryAttempts&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="breakAfterAcquireFailure"&gt; &lt;value&gt;$&#123;jdbc.pool.breakAfterAcquireFailure&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name="testConnectionOnCheckout"&gt; &lt;value&gt;$&#123;jdbc.pool.testConnectionOnCheckout&#125;&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="sessionFactory" class="org.springframework.orm.hibernate4.LocalSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;property name="hibernateProperties"&gt; &lt;props&gt; &lt;prop key="hibernate.dialect"&gt; org.hibernate.dialect.MySQLDialect &lt;/prop&gt; &lt;prop key="hibernate.show_sql"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.hbm2ddl.auto"&gt;none&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;property name="packagesToScan"&gt; &lt;list&gt; &lt;value&gt;com.niklaus.springmvc.pojo&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="hibernateTemplate" class="org.springframework.orm.hibernate4.HibernateTemplate"&gt; &lt;property name="sessionFactory"&gt; &lt;ref bean="sessionFactory" /&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 定义事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.orm.hibernate4.HibernateTransactionManager"&gt; &lt;property name="sessionFactory" ref="sessionFactory" /&gt; &lt;/bean&gt; &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;!-- 定义方法的过滤规则 --&gt; &lt;tx:attributes&gt; &lt;!-- 所有方法都使用事务 --&gt; &lt;tx:method name="*" propagation="REQUIRED" /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;aop:config&gt; &lt;!-- 定义一个切入点 --&gt; &lt;aop:pointcut id="services" expression="execution (* com.niklaus.springmvc.service.*Service.*(..))" /&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="services" /&gt; &lt;/aop:config&gt;&lt;/beans&gt; 将配置数据源的配置信息写入config.properties文件中 12345678910111213#mysql configurationjdbc.url=jdbc\:mysql\://10.1.1.00\:3306/xxxxx?autoReconnect\=true&amp;useUnicode\=true&amp;characterEncoding\=UTF-8jdbc.username=rootjdbc.password=jdbc.pool.min=5jdbc.pool.max=50jdbc.pool.maxIdleTime=180jdbc.pool.init=5jdbc.pool.idleConnectionTestPeriod=1800jdbc.pool.maxStatements=100jdbc.pool.acquireRetryAttempts=30jdbc.pool.breakAfterAcquireFailure=falsejdbc.pool.testConnectionOnCheckout=false 编写数据交互的代码创建数据表12345678910CREATE TABLE `auth_user` ( `id` INT(11) NOT NULL AUTO_INCREMENT, `username` VARCHAR(30) NOT NULL, `email` VARCHAR(75) NOT NULL, `password` VARCHAR(128) NOT NULL, `last_login` DATETIME NOT NULL, `date_joined` DATETIME NOT NULL, PRIMARY KEY (`id`), UNIQUE INDEX `username` (`username`)) Pojo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.niklaus.springmvc.pojo;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.Id;import javax.persistence.Table;import java.util.Date;/** * Created by nicholas.chi on 2016/7/2. */@Entity@Table(name = "auth_user")public class Test &#123; private long id; private String userName; private String email; private String password; private Date lastLogin; private Date dateJoined; @Id @Column(name = "id", unique = true, nullable = false) public long getId() &#123; return id; &#125; public void setId(long id) &#123; this.id = id; &#125; @Column(name = "username") public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; @Column(name = "email") public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; @Column(name = "password") public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Column(name = "last_login") public Date getLastLogin() &#123; return lastLogin; &#125; public void setLastLogin(Date lastLogin) &#123; this.lastLogin = lastLogin; &#125; @Column(name = "date_joined") public Date getDateJoined() &#123; return dateJoined; &#125; public void setDateJoined(Date dateJoined) &#123; this.dateJoined = dateJoined; &#125; @Override public String toString() &#123; return "Test&#123;" + "id=" + id + ", userName='" + userName + '\'' + ", email='" + email + '\'' + ", password='" + password + '\'' + ", lastLogin=" + lastLogin + ", dateJoined=" + dateJoined + '&#125;'; &#125;&#125; Dao层接口 12345678910111213141516171819202122package com.niklaus.springmvc.dao;import com.niklaus.springmvc.pojo.Test;import java.util.List;/** * Created by nicholas.chi on 2016/7/2. */public interface TestDao &#123; public void testAdd(Test test); public void testDelete(Test test); public void testUpdate(Test test); public Test getTestById(long id); public List&lt;Test&gt; getAll();&#125; 实现 1234567891011121314151617181920212223242526272829303132333435363738394041package com.niklaus.springmvc.dao.Impl;import com.niklaus.springmvc.dao.TestDao;import com.niklaus.springmvc.pojo.Test;import org.springframework.orm.hibernate4.HibernateTemplate;import org.springframework.stereotype.Repository;import javax.annotation.Resource;import java.util.List;/** * Created by nicholas.chi on 2016/7/2. */@Repositorypublic class TestDaoImpl implements TestDao&#123; @Resource HibernateTemplate hibernateTemplate; public void testAdd(Test test) &#123; hibernateTemplate.save(test); &#125; public void testDelete(Test test) &#123; hibernateTemplate.delete(test); &#125; public void testUpdate(Test test) &#123; hibernateTemplate.update(test); &#125; public Test getTestById(long id) &#123; Test test = hibernateTemplate.get(Test.class,id); return test; &#125; public List&lt;Test&gt; getAll() &#123; List&lt;?&gt; list = hibernateTemplate.find("from Test where id &gt; 0"); return (List&lt;Test&gt;)list; &#125;&#125; Service层接口1234567891011121314151617package com.niklaus.springmvc.service;import com.niklaus.springmvc.pojo.Test;import java.util.List;/** * Created by nicholas.chi on 2016/7/2. */public interface TestService &#123; public List&lt;Test&gt; getAllUser(); public void addUser(Test test);&#125; 实现123456789101112131415161718192021222324252627package com.niklaus.springmvc.service.Impl;import com.niklaus.springmvc.dao.TestDao;import com.niklaus.springmvc.pojo.Test;import com.niklaus.springmvc.service.TestService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;/** * Created by nicholas.chi on 2016/7/2. */@Servicepublic class TestServiceImpl implements TestService&#123; @Autowired TestDao testDao; public List&lt;Test&gt; getAllUser() &#123; return testDao.getAll(); &#125; public void addUser(Test test) &#123; testDao.testAdd(test); &#125;&#125; Controller层123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.niklaus.springmvc.controller;import com.niklaus.springmvc.pojo.Test;import com.niklaus.springmvc.service.TestService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import java.util.Date;import java.util.List;/** * Created by nicholas.chi on 2016/7/2. */@Controllerpublic class TestController &#123; @Autowired TestService testService; @RequestMapping(value="/test",method = RequestMethod.GET) public String test()&#123; List&lt;Test&gt; list = testService.getAllUser(); for(int i = 0;i&lt;list.size();i++)&#123; System.out.println("Test Num : "+i); System.out.println("Test content : "+list.get(i).toString()); &#125; return "index"; &#125; @RequestMapping(value="/testAdd",method = RequestMethod.GET) public String testAdd()&#123; Test test = new Test(); test.setUserName("Tests"); test.setEmail("test@teat.com"); test.setPassword("XXXXXXXXXXXXXXXXXXXXXX"); test.setDateJoined(new Date()); test.setLastLogin(new Date()); testService.addUser(test); return "index"; &#125;&#125; 效果验证在浏览器中访问http://localhost:10086/springmvc/test，会发现IDE的Console会打印如下信息： 123456789101112131415Hibernate: select test0_.id as id1_0_, test0_.date_joined as date_joi2_0_, test0_.email as email3_0_, test0_.last_login as last_log4_0_, test0_.password as password5_0_, test0_.username as username6_0_ from auth_user test0_ where test0_.id&gt;0Test Num : 0Test content : Test&#123;id=1, userName=&apos;kerry&apos;, email=&apos;kerry.liu@yuyutechnology.com&apos;, password=&apos;e10adc3949ba59abbe56e057f20f883e&apos;, lastLogin=2016-02-03 14:48:12.0, dateJoined=2016-02-02 18:23:13.0&#125;Test Num : 1Test content : Test&#123;id=2, userName=&apos;a&apos;, email=&apos;a@a.com&apos;, password=&apos;e10adc3949ba59abbe56e057f20f883e&apos;, lastLogin=2016-02-03 14:38:22.0, dateJoined=2016-02-03 11:29:23.0&#125;Test Num : 2Test content : Test&#123;id=3, userName=&apos;b&apos;, email=&apos;b@b.com&apos;, password=&apos;e10adc3949ba59abbe56e057f20f883e&apos;, lastLogin=2016-02-03 11:48:30.0, dateJoined=2016-02-03 11:48:30.0&#125;Test Num : 3Test content : Test&#123;id=4, userName=&apos;test&apos;, email=&apos;test@test.com&apos;, password=&apos;e10adc3949ba59abbe56e057f20f883e&apos;, lastLogin=2016-02-03 12:04:32.0, dateJoined=2016-02-03 12:03:29.0&#125;Test Num : 4Test content : Test&#123;id=5, userName=&apos;test2&apos;, email=&apos;test2@test.com&apos;, password=&apos;e10adc3949ba59abbe56e057f20f883e&apos;, lastLogin=2016-02-03 12:07:00.0, dateJoined=2016-02-03 12:07:00.0&#125;Test Num : 5Test content : Test&#123;id=6, userName=&apos;c&apos;, email=&apos;c@c.com&apos;, password=&apos;202cb962ac59075b964b07152d234b70&apos;, lastLogin=2016-02-03 12:21:44.0, dateJoined=2016-02-03 12:21:44.0&#125;Test Num : 6Test content : Test&#123;id=7, userName=&apos;123&apos;, email=&apos;123@123.com&apos;, password=&apos;dddd&apos;, lastLogin=2016-07-15 18:00:27.0, dateJoined=2016-07-15 18:00:27.0&#125; 由以上的信息可以看出，我们成功连接到了数据库，并且能从中获取我们想要的数据，但是这并不意味这我们将Spring MVC 和Hibernate整合成功了，如果我们此时去访问http://localhost:10086/springmvc/testAdd，就会发现页面提示500错误信息。 其中我们从org.springframework.dao.InvalidDataAccessApiUsageException: Write operations are not allowed in read-only mode (FlushMode.MANUAL): Turn your Session into FlushMode.COMMIT/AUTO or remove ‘readOnly’ marker from transaction definition.错误提示中可以知道，当前正处于read-only状态，只允许读操作，不允许写操作。 解决问题修改dispatcher-servlet.xml 12345678910111213141516171819202122232425262728&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd "&gt; &lt;!-- 处理静态资源 --&gt; &lt;mvc:resources location="resources" mapping="/resources/**"/&gt; &lt;!-- 启动注解驱动的Spring MVC功能，注册请求url和注解POJO类方法的映射--&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- 启动包扫描功能，以便注册带有@Controller、@Service、@repository、@Component等注解的类成为spring的bean --&gt; &lt;!--&lt;context:component-scan base-package="com.niklaus.springmvc" /&gt;--&gt; &lt;context:component-scan base-package="com.niklaus.springmvc" use-default-filters="false" &gt; &lt;context:include-filter expression="org.springframework.stereotype.Controller" type="annotation"/&gt; &lt;/context:component-scan&gt; &lt;!-- 对模型视图名称的解析，在请求时模型视图名称添加前后缀 --&gt; &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/views/" /&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;/bean&gt;&lt;/beans&gt; 修改applicationContext.xml 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;value&gt;classpath:dev/config.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;context:component-scan base-package="com.niklaus.springmvc" &gt; &lt;context:exclude-filter expression="org.springframework.stereotype.Controller" type="annotation"/&gt; &lt;/context:component-scan&gt; &lt;import resource="spring-db.xml" /&gt;&lt;/beans&gt; 保存好修改内容之后，再次访问 http://localhost:10086/springmvc/testAdd ，发现此时不再报错，然后查看数据库发现确实增加了username为Tests的 一条数据 结语直到此时我们才将Spring MVC 和 Hibernate框架初步整合，支持增删改查等一系列数据交互的操作。如果需要更加强大的功能，还需要后续的步骤。(其实我想说，你需要力量吗，氪金吧O(∩_∩)O) 参考&amp;引用更新时间发布时间 ： 2016-07-02]]></content>
      <categories>
        <category>Spring MVC菜鸟之旅</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[[Spring MVC菜鸟之旅] 通过配置文件看最简单的Spring MVC应用程序]]></title>
    <url>%2F2016%2F06%2F26%2FSpring-MVC%E8%8F%9C%E9%B8%9F%E4%B9%8B%E6%97%85-%E9%80%9A%E8%BF%87%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9C%8B%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84Spring-MVC%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[Spirng MVCSpring MVC是什么？Spring MVC是一种基于Java的实现了Web MVC设计模式的请求驱动类型的轻量级Web框架，即使用了MVC架构模式的思想，将web层进行职责解耦,基于请求驱动指的是使用请求-相应模型，框架的目的就是帮助我们简化开发，Spring MVC也是要简化我们日常Web开发的。 核心架构图 具体流程 用户发送请求 —&gt; DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制。 DispatcherServlet —&gt; HandlerMapping，HandlerMapping将会把请求映射为HandlerExecutionChain（包含一个Handler处理器（页面控制器）对象、多个HandlerInterceptor拦截器对象）对象，通过这种策略模式，很容易添加新的映射策略。 DispatcherServlet —&gt; HandlerAdapter，HandlerAdapter将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器。 HandlerAdapter —&gt; 处理器功能处理方法的调用，HandlerAdapter将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView对象（包含模型数据、逻辑视图名）。 ModelAndView逻辑视图名 —&gt; ViewResolver，ViewResolver将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术。 View —&gt; 渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术。 返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。 配置文件web.xml Java 的Web应用程序中通常都会有一个web.xml文件，这个文件是不是必须的呢？ 要回答上面的问题，首先要了解web.xml文件到底有什么用，web.xml文件是用来配置欢迎页、servlet、filter等的。如果你的应用程序中没有用到这些，自然就不需要web.xml文件了。 Spring MVC的核心是DispatcherServlet，这个Servlet充当Spring MVC的前端控制器。与其他Servlet一样，DispatcherServlet必须在Web应用程序的web.xml文件中进行配置。所以在应用程序中使用Spring MVC的第一件事就是将下面的声明放入web.xml中去： 12345&lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt; 默认情况下，DispatcherServlet在加载时会从一个基于配置名字的XML文件中加载Spring应用上下文。在这个示例中，因为servlet的名字为dispatcher，DispatcherServlet将尝试从一个名为dispatcher-servlet.xml的文件（位于应用程序的WEB-INF目录下）来加载应用上下文。 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 上面示例中声明了DispatcherServlet处理那些URL。通过将DispatcherServlet映射到 / ,声明了它会作为默认的servlet并且会处理所有的请求，包括对静态资源的请求。 dispatcher-servlet.xml根据web.xml文件的配置，我们需要在WEB-INF目录下创建dispatcher-servlet.xml文件，DispatcherServlet将使用它来创建应用上下文，而我们也将对Spring MVC的配置写在这个文件上。 静态资源访问1&lt;mvc:resources location="/resources/**" mapping="/resources/" /&gt; 正如前面所述，所有经过DispatcherServlet的请求必须以一定的方式来进行处理，而通常情况下是需要用控制器进行处理。静态资源的请求也需要通过DispatcherServlet，我们需要以某种方式来告诉DispatcherServlet如何处理这些资源。 恰好元素就是做这个的，它建立了一个服务于静态资源的处理器。属性mapping表明路径必须以/resources开始，而且也包括他的任意自路径。属性location表明了要提供服务的文件位置。以上配置表明，所有以/resources路径开头的请求都会自动由应用程序根目录下的/resources目录提供服务。因此我们的所有图片、样式表、JavaScript以及其他的静态资源都必须放在应用程序的/resources目录下。 配置注解驱动的Spring MVC在dispatcher-servlet.xml文件中添加一行配置就能得到Spring MVC所提供的注解驱动特性： 1&lt;mvc:annotation-driven /&gt; 默认扫描包路径 123456789101112Controller@RequestMapping(value="/system")public class SystemController &#123; @RequestMapping(value="/login",method=RequestMethod.GET) public ModelAndView login()&#123; ModelAndView mav = new ModelAndView("login"); System.out.println("login"); return mav; &#125;&#125; 我们先来看一下上一篇文中用作测试的SystemController，虽说比较简单，但还是有许多内容需要介绍。首先@Controller注解表明这个类是一个控制器类。这个类是@Component注解的一种具体化，也就是说将查找使用@Component注解的类并将其注册为Bean，就像它们使用@Component注解那样。 这意味着我们需要在dispatcher-servlet.xml文件中配置一个，这样SystemController类（以及将要编写的所有其他控制器）竟会自动被发现并注册为Bean。以下是相关的XML片段。 1&lt;context:component-scan base-package="com.niklaus.learn" /&gt; 解析视图处理请求的最后一件必须要做的事情就是为用户渲染输出。为了确定值定的请求需要使用哪个视图，DispatcherServlet会查找一个视图解析器来将控制器返回的逻辑视图名称转换成渲染结果的实际视图。在Spring MVC中，大量使用了约定优于配置的开发模式。InternalResourceViewResolver就是一个面向约定的元素。它将逻辑视图名称解析为View对象，而该对象将渲染的任务委托给Web应用程序上下文的一个模板（通常是JSP）。它通过为逻辑视图名称添加前缀和后缀来确定Web应用程序中的模板路径。假设我们已经将应用程序的所有JSP放在“/WEB-INF/views/”目录下。基于这样的安排，我们需要在dispatcher-servlet.xml中配置InternalResourceViewResolver，如下所示： 12345&lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView" /&gt; &lt;property name="prefix" value="/WEB-INF/views/" /&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; 参考&amp;引用 《Spring实战（第3版）》 《跟开涛学Spring MVC》 更新时间发布时间 ： 2016-06-26]]></content>
      <categories>
        <category>Spring MVC菜鸟之旅</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[[Spring MVC菜鸟之旅] 搭建一个最简单的Spring MVC应用程序]]></title>
    <url>%2F2016%2F06%2F25%2FSpring-MVC%E8%8F%9C%E9%B8%9F%E4%B9%8B%E6%97%85-%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84Spring-MVC%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[应用结构先贴上一张本文最终运行成功的Spring MVC程序的结构图 项目搭建1.使用Maven导入SpringMVC所依赖的包，修改pom.xml文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.niklaus.learning&lt;/groupId&gt; &lt;artifactId&gt;learning&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;spring.version&gt;4.3.0.RELEASE&lt;/spring.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring start --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring end --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.0-b01&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.修改WEB-INF下的web.xml1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd" id="WebApp_ID" version="3.0"&gt; &lt;!-- 配置spring核心servlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 3.在WEB-INF下创建dispatcher-servlet.xml12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd" default-lazy-init="true"&gt; &lt;!-- 处理对静态资源的请求 --&gt; &lt;mvc:resources location="/resources/**" mapping="/resources/" /&gt; &lt;!-- 添加注解驱动 --&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- 默认扫描的包路径 --&gt; &lt;context:component-scan base-package="com.niklaus.learn" /&gt; &lt;!-- 对模型视图名称的解析，在请求时模型视图名称添加前后缀 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView" /&gt; &lt;property name="prefix" value="/WEB-INF/views/" /&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt;&lt;/beans&gt; 项目测试根据dispatcher-servlet.xml配置在/WEB-INF/views下创建前台页面login.jsp123456789101112&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;LOGIN&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;Hello,World!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 根据dispatcher-servlet.xml配置的包路径，创建controller12345678910111213141516171819package com.niklaus.learn.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.servlet.ModelAndView;@Controller@RequestMapping(value="/system")public class SystemController &#123; @RequestMapping(value="/login",method=RequestMethod.GET) public ModelAndView login()&#123; ModelAndView mav = new ModelAndView("login"); System.out.println("login"); return mav; &#125;&#125; 部署项目，并访问http://localhost:8080/system/login 结束如此我们就完成了一个最为简单的SpringMVC项目 更新时间 发布时间 ： 2016-06-25]]></content>
      <categories>
        <category>Spring MVC菜鸟之旅</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何在同一台电脑配置多个git或者github账号]]></title>
    <url>%2F2016%2F06%2F18%2F%E5%A6%82%E4%BD%95%E5%9C%A8%E5%90%8C%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AAgit%E6%88%96%E8%80%85github%E8%B4%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[问题描述当有多个git账号的时候，比如一个github，用于自己进行一些开发活动，再来一个gitlab，一般是公司内部的git。这两者你的邮箱如果不同的话，就会涉及到一个问题，生成第二个git的key的时候会覆盖第一个的key，导致必然有一个用不了。 问题解决所谓多个git账号，可能有两种情况： 1 拥有多个github账号，不同的账号对应不同的repo，需要push的时候自动区分账号。 2 拥有多个git的账号，有的是github的，有个事gitlab的，不同的账号对应不同的repo url，需要push的时候自动区分账号。 这两种情况的处理方法是一样的，假设我有两个账号，一个是github上的，一个是gitlab上面的。 生成SSH Key生成第一个ssh key（这里我用于github）1ssh-keygen -t rsa -C &quot;yourmail@github.com&quot; 一路回车下去，生成结果如下图所示： 默认情况下，这个rsa秘钥是在你个人账户的.ssh目录下，存在id_rsa私钥文件和id_rsa.pub公钥文件。然后复制公钥文件中的字符串。进入github账户setting选项SSh and GPC keys，把复制的公钥字符串黏贴到Key的输入框中，保存退出即可。 通过终端ssh测试可知，出现如下提示内容，说明秘钥已经生成并且添加成功。 1ssh -T git@github.com 生成第二个ssh key（这里我用于gitLab）1ssh-keygen -t rsa -f ~/.ssh/id_rsa_gitLab -C &quot;youremail@gitLab.com&quot; 通过上面的命令，你会发现在~/.ssh目录下又多了id_rsa_gitLab和id_rsa_gitLab.pub两个文件。同样复制id_rsa_gitLab.pub公钥文件中的字符串，进入gitLab账户Profile选项SSH keys下，把复制的公钥字符串黏贴到Key的输入框中，保存退出即可。 添加秘钥到SSH agent因为默认只读取id_rsa,为了让SSH识别新的私钥，需将其添加的SSH agent中。这里如果你用的github官方的bash，ssh-agent -s,如果是其他的，比如msysgit,eval $(ssh-agent -s) 如果出现 Could not open a connection to your authentication agent 的错误，就是这用一下命令： 123ssh-agent bashssh-add ~/.ssh/id_rsa_gitssh-add ~/.ssh/id_rsa_gitLab 最后可以通过下面命令，查看key的设置 1ssh-add -l 创建并配置config文件在windows下新建一个txt文本，然后将名字后缀一起改成config即可；而在Linux下的话，在.ssh 目录下，直接vim config,如果在bash下，可以通过以下命令生成config文件 1touch config 向空白的config文件中添加一下内容 12345678910111213# gitlabHost git.aspectgaming.comHostName git.aspectgaming.com PreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsa_gitLabUser nicholas.chi# githubHost github.comHostName github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsaUser git 测试 补充如果之前有设置全局用户名和邮箱的话，需要unset一下 12git config --global --unset user.namegit config --global --unset user.email 然后在不同的仓库下设置局部的用户名和邮箱 12git config user.email “xxxx@xx.com”git config user.name “xxxx 这样，以后每次在对应的repo下提交修改，都会自动匹配相应的SSH-Key。 参考&amp;引用管理git生成的多个ssh key 一台电脑存放多个git账户的多个rsa秘钥 如何同一台电脑配置多个git或github账号 更新时间发布时间 ： 2016-06-18]]></content>
  </entry>
  <entry>
    <title><![CDATA[git将本地仓库上传到远程仓库]]></title>
    <url>%2F2016%2F06%2F11%2Fgit%E5%B0%86%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E4%B8%8A%E4%BC%A0%E5%88%B0%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[目的在已有的git库中搭建新库，并且将本地的git仓库，上传到远程服务器的git库中，从而开始一个新的项目。 不登录远程git服务器直接本地操作初始化仓库1git init 该命令将创建一个名为.git的子目录，这个子目录含有你初始化的git仓库中所有的必须文件，这些文件是Git仓库的骨干。但是，在这个时候，我们仅仅是做了一个初始化的操作，你的项目里的文件还没有被跟踪。 对指定文件的追踪1git add . 提交操作1git commit -m &apos;first commit&apos; 当使用 git commit 进行提交操作时，Git 会先计算每一个子目录（本例中只有项目根目录）的校验和，然后在 Git 仓库中这些校验和保存为树对象。 随后，Git 便会创建一个提交对象，它除了包含上面提到的那些信息外，还包含指向这个树对象（项目根目录）的指针。如此一来，Git 就可以在需要的时候重现此次保存的快照 添加远程仓库1git remote add origin git@xx.xx.xx.xx:repos/xxx/xxx/xxx.git 推送本地分支到远程仓库1git push origin (remote):(branch) 推送本地的 remote 分支，将其作为远程仓库的 branch 分支，可以通过这种格式来推送本地分支到一个命名不相同的远程分支。 出现问题问题1the file will have its original line endings in your working directory 1git config --global core.autocrlf false 问题2fatal:unable to access ‘xxx/xxx/xxx/…’:Filename too long 相关问题Filename too long in git for windows 1git config --global core.longpaths true 问题3fatal: Not a valid object name: ‘master’ 相关问题git 错误 fatal: Not a valid object name: ‘master’. 问题4error:dst ref refs/heads/source receives form more than one src. 1git push origin (remote):(branch) 在remote与branch中间的：不要遗漏，否则就会出现以上问题 参考&amp;引用git官方文档 git将本地仓库上传到远程仓库 更新时间发布时间 ： 2016-06-11]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ Idea使用那些事]]></title>
    <url>%2F2016%2F06%2F04%2FIntelliJ-Idea%E4%BD%BF%E7%94%A8%E9%82%A3%E4%BA%9B%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[配置JettyRun/Debug Configurations按下图标识打开Run/Debug Configurations面板 commond line 添加配置1org.mortbay.jetty:maven-jetty-plugin:6.1.22:run 修改端口Runner选项-&gt;VM Options 设置 1-Djetty.port=10086 pom文件添加plugin12345678910&lt;build&gt; &lt;finalName&gt;springmvc&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.2.1.v20140609&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 参考&amp;引用更新时间发布时间 ： 2016-06-04]]></content>
      <tags>
        <tag>IntelliJ Idea</tag>
      </tags>
  </entry>
</search>